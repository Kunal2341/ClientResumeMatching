{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil #Controlling Files and paths and folder control\n",
    "from shutil import copyfile\n",
    "from pdf2image import convert_from_path #Libary convert pdf file to img file\n",
    "from google.oauth2 import service_account #Control API Keys\n",
    "from google.cloud import vision # Vision API from Google\n",
    "import io\n",
    "import string, random\n",
    "import pandas as pd\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import unicode_literals, print_function\n",
    "#from spacy.lang.en import English # updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF TO TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths that have all folders which use everything\n",
    "pdfIMGPopplerPath = '/Users/kunal/Documents/VdartResumeProject/Poppler/poppler-0.68.0_x86/poppler-0.68.0/bin/'\n",
    "imgTxtVisionAPIPath = \"/Users/kunal/Documents/VdartResumeProject/APIKEYSGOOGLE/resumeMatcher-pdf2img.json\"\n",
    "runningDocumentPath = '/Users/kunal/Documents/VdartResumeProject/runningDoc/'\n",
    "sourceFolderResumesPath = '/Users/kunal/Documents/VdartResumeProject/50_resumes/'\n",
    "excelFilesPath = '/Users/kunal/Documents/VdartResumeProject/ExcelFiles/'\n",
    "nlpAutoAPIPath = \"/Users/kunal/Documents/VdartResumeProject/APIKEYSGOOGLE/resumeMatcher-NLP_create_data.json\"\n",
    "jsonFolderPath = '/Users/kunal/Documents/VdartResumeProject/JSONLFILES/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_2_image(uploaded_image_path, uploaded_image):\n",
    "    #Using the convert_from_path function\n",
    "    #Same name as pdf but converted to img\n",
    "    #Watch out for poppler -- necceasary to function\n",
    "    os.chdir(uploaded_image_path) # Change the working diretory to path that contains the PDF file\n",
    "    file_name = str(uploaded_image).replace('.pdf','') # file name for png still going to get changed later\n",
    "    pages = convert_from_path(uploaded_image, 200,poppler_path=pdfIMGPopplerPath) #function to change pdf to img\n",
    "    pageNumCount = 1 #numbering for all the different images if pdf is multiple pages\n",
    "    outputNames = []\n",
    "    for page in pages:\n",
    "        output_file = file_name+\"_\"+str(pageNumCount) + '.jpg'#uptaded name for image\n",
    "        page.save(output_file, 'JPEG')#save img\n",
    "        pageNumCount +=1\n",
    "        outputNames.append(output_file)\n",
    "    return outputNames #names of img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_2_text(imagePath):\n",
    "    #Using API from Google\n",
    "    #Returns a JSON file but text is extracted from it\n",
    "    keyDIR = imgTxtVisionAPIPath #JSON key file to call the api\n",
    "    credentials = service_account.Credentials.from_service_account_file(keyDIR) #using service account to go through google\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials) # client api\n",
    "    with io.open(imagePath, 'rb') as image_file: #opening and reading img\n",
    "        content = image_file.read() \n",
    "    image = vision.types.Image(content=content) # calling and running the client Visison API\n",
    "    response = client.text_detection(image=image) # JSON return with all values\n",
    "    texts = response.text_annotations # Go through Json and extract the text detected\n",
    "    totalString = ''\n",
    "    for text in texts:\n",
    "        totalString+=text.description\n",
    "    totalString = totalString.rsplit(' ', 1)[0] # throws away all the metadata with location -- could be used later\n",
    "    return totalString #TEXT detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteIMG(path):\n",
    "    #Deletes all the images from a folder\n",
    "    for i in os.listdir(path):\n",
    "        if i.endswith(\".jpg\"):\n",
    "            os.remove(folder_pdf + i)\n",
    "def deleteEverythingInFolder(folder_pdf):\n",
    "    #deletes everything in the folder including folders and files\n",
    "    for file in os.listdir(folder_pdf):\n",
    "        try:\n",
    "            shutil.rmtree(folder_pdf+ file) #remove folder\n",
    "        except NotADirectoryError:\n",
    "            try:\n",
    "                os.remove(folder_pdf+ file) # if it is not a folder than it is a file so it removes it also\n",
    "            except:\n",
    "                pass\n",
    "def moveRenameAllFiles(sourceFolderResumes, folder_pdf):\n",
    "    #Moves all files from source and renames them starting from 100\n",
    "    #If start from 1 then the ordering will be off\n",
    "    for realFile in os.listdir(sourceFolderResumes):\n",
    "        copyfile(sourceFolderResumes + realFile, folder_pdf + realFile) #duplicates all the files from source\n",
    "    os.chdir(folder_pdf) # move them to the running folder\n",
    "    documentcounter = 100 # names \"Dociment_[num].pdf\" start from 100 cause that is how numbering is listed correctly\n",
    "    for i in os.listdir(folder_pdf):\n",
    "        fileNameCreator = \"Document_\" + str(documentcounter) + \".pdf\"\n",
    "        print(i + \"   changed to  \" + fileNameCreator)\n",
    "        os.rename(i, fileNameCreator)  # change name of file\n",
    "        documentcounter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_pdf = runningDocumentPath # set var\n",
    "sourceFolderResumes = sourceFolderResumesPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document_402.pdf   changed to  Document_100.pdf\n",
      "Document_403.pdf   changed to  Document_101.pdf\n",
      "Document_405.pdf   changed to  Document_102.pdf\n",
      "Document_406.pdf   changed to  Document_103.pdf\n",
      "Document_407.pdf   changed to  Document_104.pdf\n",
      "Document_408.pdf   changed to  Document_105.pdf\n",
      "Document_409.pdf   changed to  Document_106.pdf\n",
      "Document_410.pdf   changed to  Document_107.pdf\n",
      "Document_411.pdf   changed to  Document_108.pdf\n",
      "Document_412.pdf   changed to  Document_109.pdf\n",
      "Document_413.pdf   changed to  Document_110.pdf\n",
      "Document_414.pdf   changed to  Document_111.pdf\n",
      "Document_415.pdf   changed to  Document_112.pdf\n",
      "Document_417.pdf   changed to  Document_113.pdf\n",
      "Document_418.pdf   changed to  Document_114.pdf\n",
      "Document_419.pdf   changed to  Document_115.pdf\n",
      "Document_420.pdf   changed to  Document_116.pdf\n",
      "Document_421.pdf   changed to  Document_117.pdf\n",
      "Document_422.pdf   changed to  Document_118.pdf\n",
      "Document_423.pdf   changed to  Document_119.pdf\n",
      "Document_424.pdf   changed to  Document_120.pdf\n",
      "Document_425.pdf   changed to  Document_121.pdf\n",
      "Document_426.pdf   changed to  Document_122.pdf\n",
      "Document_427.pdf   changed to  Document_123.pdf\n",
      "Document_428.pdf   changed to  Document_124.pdf\n",
      "Document_429.pdf   changed to  Document_125.pdf\n",
      "Document_430.pdf   changed to  Document_126.pdf\n",
      "Document_431.pdf   changed to  Document_127.pdf\n",
      "Document_432.pdf   changed to  Document_128.pdf\n",
      "Document_433.pdf   changed to  Document_129.pdf\n",
      "Document_434.pdf   changed to  Document_130.pdf\n",
      "Document_435.pdf   changed to  Document_131.pdf\n",
      "Document_436.pdf   changed to  Document_132.pdf\n",
      "Document_437.pdf   changed to  Document_133.pdf\n",
      "Document_438.pdf   changed to  Document_134.pdf\n",
      "Document_474.pdf   changed to  Document_135.pdf\n",
      "Document_475.pdf   changed to  Document_136.pdf\n",
      "Document_476.pdf   changed to  Document_137.pdf\n",
      "Document_477.pdf   changed to  Document_138.pdf\n",
      "Document_478.pdf   changed to  Document_139.pdf\n",
      "Document_479.pdf   changed to  Document_140.pdf\n",
      "Document_480.pdf   changed to  Document_141.pdf\n",
      "Document_481.pdf   changed to  Document_142.pdf\n",
      "Document_482.pdf   changed to  Document_143.pdf\n",
      "Document_483.pdf   changed to  Document_144.pdf\n",
      "Document_484.pdf   changed to  Document_145.pdf\n",
      "Document_485.pdf   changed to  Document_146.pdf\n",
      "Document_486.pdf   changed to  Document_147.pdf\n",
      "Document_487.pdf   changed to  Document_148.pdf\n",
      "Document_488.pdf   changed to  Document_149.pdf\n"
     ]
    }
   ],
   "source": [
    "deleteEverythingInFolder(folder_pdf)\n",
    "moveRenameAllFiles(sourceFolderResumes, folder_pdf)\n",
    "numberOfFiles = len([name for name in os.listdir(folder_pdf) if os.path.isfile(name)]) \n",
    "#PNGFilesExist = checkifPNGExists(folder_pdf)\n",
    "#deletes everything in the folder, copy and moves all files and renames them starting from 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which Document do you wanna run?115\n",
      "True\n",
      "You choose a specific number so your document is Document_115.pdf\n"
     ]
    }
   ],
   "source": [
    "#Asks the user which document they want to run and if they don't input anything, its a random document\n",
    "doubleCheckDocumentInputCount = 0\n",
    "while True:\n",
    "    documentRun = input(\"Which Document do you wanna run?\")\n",
    "    if documentRun == \"\" and doubleCheckDocumentInputCount >= 1:\n",
    "        documentRun = (random.choice(os.listdir(folder_pdf)))\n",
    "        print(\"You choose RANDOM so your document is \" + documentRun)\n",
    "        break\n",
    "    elif documentRun == \"\":\n",
    "        print(\"This is a double check if you want a random document?\")\n",
    "        doubleCheckDocumentInputCount+=1\n",
    "    elif documentRun == \"BREAK\":\n",
    "        print(\"Exiting\")\n",
    "        documentRun = \"INVALID\"\n",
    "        break\n",
    "    else:\n",
    "        documentRun = \"Document_\" + documentRun + \".pdf\"\n",
    "        print(os.path.isfile(folder_pdf + documentRun))\n",
    "        if os.path.isfile(folder_pdf + documentRun):\n",
    "            print(\"You choose a specific number so your document is \" + documentRun)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Document was invalid. Input >>> BREAK <<< to stop\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kunal/Documents/VdartResumeProject/runningDoc/Fold_Document_115/\n",
      "Document_115.pdf\n",
      "Running Number: 2\n",
      "Document_115_1.jpg Document_115_2.jpg \n"
     ]
    }
   ],
   "source": [
    "#Makes a folder and create images of each page in PDF document\n",
    "textList = []\n",
    "numberPagesList = []\n",
    "for i in os.listdir(folder_pdf): \n",
    "    if i == documentRun:# only runs the file that was choosen by user\n",
    "        os.chdir(folder_pdf) \n",
    "        folderNameCreate = folder_pdf+\"Fold_\"+i[:-4]+\"/\" \n",
    "        print(folderNameCreate)\n",
    "        os.mkdir(folderNameCreate) #Create folder\n",
    "        shutil.move(i,folderNameCreate) #MovePDF into folder\n",
    "        os.chdir(folderNameCreate)\n",
    "        for j in os.listdir(folderNameCreate):\n",
    "            print(j)\n",
    "            if j.endswith(\".pdf\"): \n",
    "                imgName = convert_pdf_2_image(folderNameCreate, j) #call pdf2img function\n",
    "                print(\"Running Number: \" + str(len(imgName))) \n",
    "                printString = \"\"\n",
    "                for docName in imgName: # for making the printing better\n",
    "                    printString += docName + \" \" \n",
    "                print(printString) \n",
    "            for q in range(len(imgName)):\n",
    "                text = convert_img_2_text(folderNameCreate + i[:-4] + \"_\" + str(q+1) + \".jpg\")\n",
    "                textList.append(text)     #Convert to text and append all the text to list\n",
    "                numberPagesList.append(len(imgName))   \n",
    "    else:\n",
    "        os.chdir(folder_pdf) #delete any other file that exists\n",
    "        os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()  # creates a tabel with all the text and pages\n",
    "df['Text Extracted'] = textList\n",
    "df['DocumentNum'] = numberPagesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(excelFilesPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCELFILENAME = documentRun[:-4] + \"_text.xlsx\"\n",
    "df.to_excel(EXCELFILENAME, index = False) # save the text to the excel file folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCELFILENAME = documentRun[:-4] + \"_text.xlsx\" # read the same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(excelFilesPath) # change working path to excel files folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.ExcelFile(EXCELFILENAME) \n",
    "dftext = text.parse(\"Sheet1\") # read the file to see what was saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Extracted</th>\n",
       "      <th>DocumentNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SCOTT JOHNSON\\nCumming, GA ·(937) 903-6163\\n• ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Worked with various internal teams to help sup...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Extracted  DocumentNum\n",
       "0  SCOTT JOHNSON\\nCumming, GA ·(937) 903-6163\\n• ...            2\n",
       "1  Worked with various internal teams to help sup...            2"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = dftext[\"Text Extracted\"].tolist() # converts both columns to lists \n",
    "pagesList = dftext[\"DocumentNum\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Recommendation letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "numb = 0\n",
    "recNumList=[]\n",
    "for i in text_list: # for all the text files scan if the word recommendation is in there\n",
    "    if \"Recommendation\" in str(i): \n",
    "        recNumList.append(numb)\n",
    "    numb+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recNumList # print all the page numbers with the word in it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts the text files to an array but still split into pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runningTextFINAL = '\\n'.join(textList) # the text is combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCOTT JOHNSON\n",
      "Cumming, GA ·(937) 903-6163\n",
      "• johnsons71@yahoo.com ·\n",
      "As an\n",
      "environment, I am seeking a position with a company that will utilize my\n",
      "problem-solving and analytical skills as well as my understanding of\n",
      "advanced accounting concepts.\n",
      "<perienced and detailed team accountant in a multi-group\n",
      "EXPERIENCE\n",
      "03/2014 - 09/2019\n",
      "11/2009 - 10/2011\n",
      "SR. OPERATIONAL AND ACCOUNTING CONSULTANT, METLIFE\n",
      "RETIREMENT & INCOME SOLUTIONS\n",
      "Cash account reconciliations - reconciled twenty-one cash\n",
      "accounts across five business groups (Stable Value/Commercial\n",
      "Paper, Structured Settlements, Income Annuities, Separate\n",
      "Accounts, Pensions Direct Payment) daily to ensure\n",
      "incoming/outgoing payments cleared and accounting generated\n",
      "properly\n",
      "Suspense/clearing account reconciliations - reconciled twelve\n",
      "suspense/clearing accounts to ensure accounting generated\n",
      "properly for premium/benefits accounts\n",
      "Manual journal entries - cash and suspense reclass, accrual,\n",
      "adjusting, closing\n",
      "Lockbox/Wire/ACH Monitoring - Chase Bank and Wells Fargo - US\n",
      "liaison to resolve all premium issues for Income Annuities and\n",
      "Structured Settlements with Operations team in India\n",
      "Month end reporting for US Controllers/Reserves - reviewed high\n",
      "dollar transaction with US Controllers to confirm reporting is in\n",
      "proper periods due to system limitations; additional reporting for\n",
      "Reserves to confirm reserve values are accurate\n",
      "Audit Requests - Internal and external pertaining to SOX and\n",
      "SSAE 16 audits\n",
      "System Training/Testing Custom web-based application -\n",
      "training on accounting rules and premium processing, testing for\n",
      "deployments of new business groups on this platform\n",
      "Training - trained three new associates on duties transferring to\n",
      "Tampa, Florida, from initial receipt of funds to reconciliation\n",
      "System Application Owner - System access \"Gatekeeper\" for\n",
      "audit; approved access, system access issues, internal\n",
      "Worked with various internal teams to help support accounting\n",
      "function for discrepancies/accounting failures\n",
      "EDUCATION\n",
      "06/2006 - 11/2008\n",
      "SINCLAIR COMMUNITY COLLEGE, DAYTON, OHIO\n",
      "SKILLS\n",
      "Microsoft Suite\n",
      "(Excel/Word/Outlook/OneDrive)\n",
      "TrinTech ReconNet\n",
      "ViTech custom web-based\n",
      "administration system\n",
      "PeopleSoft (general and sub-ledger)\n",
      "Wells Fargo Lockbox Portal\n",
      "Four custom Mainframe\n"
     ]
    }
   ],
   "source": [
    "print(runningTextFINAL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "textChoosen = runningTextFINAL # set variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "setnecnceAuto = []\n",
    "for line in textChoosen.splitlines(): # function that splits all the text by lines, this is all automatic and not accurate\n",
    "    setnecnceAuto.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAR: 7323, LINES: 139\n"
     ]
    }
   ],
   "source": [
    "print(\"CHAR: \" + str(len(textChoosen)) + \", LINES: \" + str(len(setnecnceAuto))) # print some information about the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: >>><<< + >>>NISARGA HASSAN SREEDHAR<<<\n",
      "Current: >>>NISARGA HASSAN SREEDHAR <<< + >>>San Jose, California |+1 (925) 789-8911| nisarga.nishu20@gmail.com | www.linkedin.com/in/nisarga-sreedhar-39938516b<<<g\n",
      "Added >>>NISARGA HASSAN SREEDHAR<<<\n",
      "Current: >>><<< + >>>San Jose, California |+1 (925) 789-8911| nisarga.nishu20@gmail.com | www.linkedin.com/in/nisarga-sreedhar-39938516b<<<\n",
      "Current: >>>San Jose, California |+1 (925) 789-8911| nisarga.nishu20@gmail.com | www.linkedin.com/in/nisarga-sreedhar-39938516b <<< + >>>EDUCATION:<<<g\n",
      "Added >>>San Jose, California |+1 (925) 789-8911| nisarga.nishu20@gmail.com | www.linkedin.com/in/nisarga-sreedhar-39938516b<<<\n",
      "Current: >>><<< + >>>EDUCATION:<<<\n",
      "Current: >>>EDUCATION: <<< + >>>Master's in Electrical Engineering (Computer Networking), San Jose State University, California, USA.<<<\n",
      "Current: >>>EDUCATION: Master's in Electrical Engineering (Computer Networking), San Jose State University, California, USA. <<< + >>>Coursework: Internetworking, Broadband communications, Network Security, Internet of Things (IoT), Voice over IP<<<g\n",
      "Added >>>EDUCATION: Master's in Electrical Engineering (Computer Networking), San Jose State University, California, USA.<<<\n",
      "Current: >>><<< + >>>Coursework: Internetworking, Broadband communications, Network Security, Internet of Things (IoT), Voice over IP<<<fff\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\n",
    "sentenceList = []\n",
    "char = 0\n",
    "addNumChar = (int(len(textChoosen)/(len(setnecnceAuto))))+1\n",
    "for j in range(len(setnecnceAuto)): # loops through all the sentences that were created automatically\n",
    "    #print([str(j) + \" \" + textChoosen[char:char + addNumChar]])\n",
    "    char += addNumChar\n",
    "    addword = input(\"Current: >>>\"+ sentence+ \"<<< + >>>\"+ setnecnceAuto[j] + \"<<<\") \n",
    "    #asks if they want to add the next sentence to the current running sentence\n",
    "    if addword == \"\": #if nothing inputed, it combines the sentence and waits for next value\n",
    "        sentence += setnecnceAuto[j] + \" \"\n",
    "    elif addword == \"g\": # if \"g\" then it saves the current running sentence and then reset to 0 and continue from there\n",
    "        sentenceList.append(sentence[:-1])\n",
    "        print(\"Added >>>\"+sentence[:-1]+\"<<<\")\n",
    "        sentence = \"\"\n",
    "        setnecnceAuto[j: j] = [\"testfff\"]\n",
    "    elif addword == \"fff\": # break everything and stop \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceList= setnecnceAuto #var names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre made sentence list by Kunal\n",
    "sentenceList = ['Oleg Kotliarsky',\n",
    " '(720) 987-8054',\n",
    " 'olegkot@gmail.com',\n",
    " 'Profile highlights:',\n",
    " 'Web Development Engineer',\n",
    " 'Vast experience designing, programming and leading enterprise web applications development',\n",
    " 'Proficient in optimal UX solutions',\n",
    " 'Great experience in developing reusable components to optimize development time and maintenance',\n",
    " 'Ability to provide technical leadership and clear guidance to development team',\n",
    " 'High skills to research, evaluate and implement right technical solution for the enterprise application',\n",
    " 'Technical Knowledge:',\n",
    " 'JavaScript, TypeScript, ReactJS, Action Script 3.0, Java, PHP',\n",
    " 'Angular, AngularJS, RXJS, Karma, Java Spring, İBATIS, Apache Struts',\n",
    " 'Oracle, MongoDB, SQL Server, MYSQL',\n",
    " 'angular-cli, npm, bower, gulp, GIT',\n",
    " 'Languages:',\n",
    " 'Frameworks:',\n",
    " 'Databases:',\n",
    " 'Tools:',\n",
    " 'Professional Experience: Aug. 2017 - April 2020 Senior Web Developer, Comcast, CO',\n",
    " 'Designed and developed new app features (Columbo - ESL). (Angular6/Angular UI, Remedy, JAVA, Oracle DB):',\n",
    " 'data driven \"case create wizard\" with back-end precheck and dynamic restructure of the steps',\n",
    " '- case resolve \"stepper\" with variable number of corresponding relative issues',\n",
    " '- reusable components - \"keyword\" search, attachments list, \"add attachments\", PDF viewer, util service with multitude of helper functions.',\n",
    " '- HTTP request wrappers, HTTP response interceptor for unified error handling',\n",
    " 'Developed a web app (Columbo - Executive Support Line). (Hybrid AngularJS/Angular UI, Remedy, JAVA, Oracle DB); Maintain and support GIT Hub of the project',\n",
    " 'Dec. 2013 – June 2017 Senior UI Developer / Team Lead / Scrum Master, DN2K, CO',\n",
    " 'Developed customers, search, navigation modules for \"MyDairyCentral\" web app portal, sensors tiles carousel, responsive design, etc. (Angular4, angular-cli, Jasmine/Karma)',\n",
    " 'Developed sensors tiles carousel, set karma unit tests framework for \"MyGrowCentral\" web app portal (AngularJS, Node, responsive design, JHipster, Jasmine/Karma)',\n",
    " 'Developed different features of the \"MyAGCentral\" web app portal, including navigation tree, work orders flow, etc. (AngularJS, Node, Mongo) - client Sagelnsights: https://www.sageinsights.com/',\n",
    " 'Transitioned from Backbone to Angular framework (team effort) of the \"MyAGCentral\" web app portal',\n",
    " 'October 2011 - Dec. 2013 Web Developer Expert, Amdocs Inc., CO',\n",
    " 'Developed \"Order Entry\" web application for entering order to the Amdocs Enterprise order management system (HTML5/CSS3, JavaScript/jQuery, AJAX/DWR, JSP/Java 7, Oracle, Java Spring, iBatis)',\n",
    " 'Developed e-signature web app using previously developed JavaScript/jQuery/JSP/Java6/Spring2 framework for sending client\\'s contract to \"on-the-fly\" signature creation (integration with docusign.com service).',\n",
    " 'Developed part of the real time payment integration flow utilizing Amdocs EAI framework called JESI. (Java, JSP, SOAP, Oracle, JavaScript, jQuery)',\n",
    " 'Developed Flex \"Executive Advisor\" report tool for serving different types of client statistics presented in a rich graphic interactive way (Flex 4.6, Blaze DS, Java, Oracle, Action Script 3)',\n",
    " 'October 2010 – Oct. 2011 Web Developer Contractor, Rose International (for Amdocs Inc.), CO',\n",
    " 'Developed iLink Mobile app (running on iPad Safari – used home developed framework) for sales representatives [client: DexOne]. (JavaScript, jQuery, jQTouch, AJAX, HTML5/webkit, Java, Spring, iBatis, Oracle, JSP);',\n",
    " 'Developed an iPad web application framework for rapid development of iOS apps that look like',\n",
    " 'March 2009 - October 2010 GSET Engineer, Wall Street on Demand (now Markit on Demand), Boulder, CO',\n",
    " 'Developed Entitlements management intranet tool [client: Goldman Sachs]. (Java, Struts, Sybase, JSP, JavaScript, jQuery, AJAX);',\n",
    " 'March 2008 – March 2009 Team Lead Developer, Wall Street on Demand (now Markit on Demand), Boulder, CO',\n",
    " 'Leaded team of web developers, working on line of Stocks Research Websites [client: Schwab Institutional] (ASP, JavaScript, AJAX);',\n",
    " 'August 2005 – March 2008 Senior Web Developer, Wall Street on Demand (now Markit on Demand), Boulder, CO',\n",
    " 'Developed Web site architecture and determine software requirements.',\n",
    " 'Created and optimized content for the Web site, including planning, design, integration and testing of Web-site related code.',\n",
    " 'Planned and designed new featured web sites according to client requirements. Close interaction with graphic designers, project managers and QA members of our group;',\n",
    " 'Developed Real Time DB driven web sites with Stocks market content, including price quotes graphics, charts, news, alerts etc. Schwab group projects (ASP, JScript, JavaScript, AJAX);',\n",
    " 'April 2004 – August 2005 Freelancer Web Developer, Denver, CO',\n",
    " 'Developed full code circle from templates to launch (PHP/MySql, JavaScript, HTML, CSS);',\n",
    " 'Created Graphics: logos, bullets, complete design (Photoshop, Flash MX);',\n",
    " 'Promoted web sites in search engines positioning (1st page positions in Google, Yahoo on several key words).',\n",
    " 'April 2003 – April 2004',\n",
    " 'Web developer, Gteko (purchased by Microsoft), Raanana, Israel',\n",
    " '- Developed JavaScript/VBScript active client side (ActiveX event\\'s handling flow: version checking, upgrading, downloading and installation) of different \"e-support\" accounts (HP, Canon, AOL, Dell, NEC, Lenovo, etc)',\n",
    " 'Developed JavaScript classes reflecting graphic presentation of ActiveX control downloading and installation processes;',\n",
    " 'Developed a full JavaScript based interface for ActiveX control data processing - JavaScript/DOM/DHTML based model for PC scanned data show. Was a leading developer for GTWebCheck product part called \"Upgrade Advisor\" or \"Summary Report\".',\n",
    " 'June 2002 – April 2003 Freelancer Web developer, Tel-Aviv , Israel',\n",
    " 'Complete web sites production (Programming development, PHP/MYSQL/JavaScript/HTML/CSS index + forum (OOP);',\n",
    " \"Created graphic design according to Client's requirements (logo, bullets, layout – Photoshop, Flash); Made domain name registration; Assisted in identity development, marketing, online promotion and launch;\",\n",
    " 'Maintained web mastering; Promoted web sites for search engines positioning August 1999 - May 2002',\n",
    " 'Web Developer, Snapshield Ltd, Tel Aviv, Israel',\n",
    " \"Created Web design (Photoshop, Flash) for Web based application for remote data management for tens of thousands of clients of the leading Snapshield's Telecom Encryption Service (SNAP);\",\n",
    " 'Programmed part of the SNAP application (Customer Care) using ASP, JavaScript, VBScript, CSS, IIS 4;',\n",
    " 'Set required configuration for SSL on MS IIS4.',\n",
    " 'Created web based client-side application \"Snapshield\\'s Security Algorithm Benchmark\" for dynamic online calculating and show for different TI DSP platforms and Snapshield algorithms. (ASP, CSS, DHTML)',\n",
    " 'Created Flash Animated Company Business and Technical Presentations (online, cds) in Macromedia',\n",
    " 'Flash 5; Integrated video streaming to companies web site (JavaScript, DHTML)',\n",
    " 'Created graphic and technical design, developed, published and web mastered three generations of the\\ncompany\\'s web site. (HTML/DHTML, JavaScript, CSS, Macromedia Flash 5, Adobe Photoshop 5.5;',\n",
    " 'Assisted in new branding process (migrating from Microlink to Snapshield)',\n",
    " 'Education:',\n",
    " 'BS and MS in Mathematics and Mechanics',\n",
    " 'St. Petersburg State University',\n",
    " 'Courses:',\n",
    " '\"Oracle Certified Associate\", iTerra Consulting, Ic., Denver, USA.',\n",
    " '\"Design for Multimedia\", ORT Syngalovsky College, Tel Aviv. (800 hours)',\n",
    " '\"JavaScript - DHTML – DOM\", Sela group, Tel Aviv (30 hours)',\n",
    " '\"OOD/OOP for C++ and Java\", \"Network TCP/IP\", Tel-Ran, Rishon-Lezion (1000 hours)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Entity Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cloud.google.com/natural-language/docs/basics#entity_analysis\n",
    "def extractMajorEntities(text_content, salienceScoreThres):\n",
    "    keyDIR = nlpAutoAPIPath # JSON path with the crediatials \n",
    "    credentials = service_account.Credentials.from_service_account_file(keyDIR) # same as before api credentials\n",
    "    client = language_v1.LanguageServiceClient(credentials=credentials)  # language client \n",
    "    type_ = enums.Document.Type.PLAIN_TEXT \n",
    "    language = \"en\" # english text\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language} #formatting the design of api input -- leave it\n",
    "    encoding_type = enums.EncodingType.UTF8 # reading the document -- must have \n",
    "    response = client.analyze_entities(document, encoding_type=encoding_type) # actual run of the api\n",
    "    majorValues = []\n",
    "    for entity in response.entities:  #reading the JSON that was returned by analyze entities\n",
    "        if entity.salience > salienceScoreThres: #salience score is the importance of the entity compared to the full document\n",
    "            majorValues.append([entity.name,entity.salience]) # if it is greater than the threshold then save it and return it\n",
    "    return  majorValues\n",
    "def extractEntities(text_content):\n",
    "    keyDIR = nlpAutoAPIPath# JSON path with the crediatials \n",
    "    credentials = service_account.Credentials.from_service_account_file(keyDIR) # same as before api credentials\n",
    "    client = language_v1.LanguageServiceClient(credentials=credentials) # language client\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "    language = \"en\"# english text\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}#formatting the design of api input -- leave it\n",
    "    encoding_type = enums.EncodingType.UTF8# reading the document -- must have \n",
    "    response = client.analyze_entities(document, encoding_type=encoding_type) # actual run of the api\n",
    "    nonuseEntities = [\"OTHER\", \"NUMBER\"] # attributes of the entities that dont matter and are of no use\n",
    "    allEntitiesExtracted = []\n",
    "    for entity in response.entities: # loop through json and see all entities\n",
    "        currentRunningEntity = []\n",
    "        #print(entity.name)\n",
    "        #print(enums.Entity.Type(entity.type).name)\n",
    "        if enums.Entity.Type(entity.type).name not in nonuseEntities: # check if meta data from entity is important\n",
    "            #print(\"Detected \" + entity.name + \" as \" + enums.Entity.Type(entity.type).name)\n",
    "            currentRunningEntity.append(entity.name)\n",
    "            currentRunningEntity.append(enums.Entity.Type(entity.type).name)\n",
    "            allEntitiesExtracted.append(currentRunningEntity) # append it to list \n",
    "        else: \n",
    "            for mention in entity.mentions:\n",
    "                if enums.EntityMention.Type(mention.type).name == \"PROPER\":\n",
    "                    #print(\"Detected \" + mention.text.content + \" as \" + enums.EntityMention.Type(mention.type).name)\n",
    "                    currentRunningEntity.append(mention.text.content)\n",
    "                    currentRunningEntity.append(enums.EntityMention.Type(mention.type).name)\n",
    "                    allEntitiesExtracted.append(currentRunningEntity) # another check if it entity is important \n",
    "                    # must see format or return entity to see how this is working \n",
    "        #allEntitiesExtracted.append(currentRunningEntity) if currentRunningEntity != [] else print(\"-\")\n",
    "        #allEntitiesExtracted.append(currentRunningEntity)   \n",
    "    finalArray = []\n",
    "    runningEnitityCount = 0\n",
    "    positionValuesEnitiesList = []\n",
    "    for i in range(len(allEntitiesExtracted)):\n",
    "        arrayrun = []\n",
    "        arrayrun.append(allEntitiesExtracted[i][0])\n",
    "        arrayrun.append(allEntitiesExtracted[i][1])\n",
    "        arrayrun.append(text_content.find(allEntitiesExtracted[i][0]))\n",
    "        positionValuesEnitiesList.append(arrayrun)\n",
    "    positionValuesEnitiesList = sorted(positionValuesEnitiesList, key=lambda x: x[2]) # sort everything by what is first \n",
    "    #print(positionValuesEnitiesList)\n",
    "    # some of the entities should be combined together becuase they are 2 words and they both fit the position of what the \n",
    "    # entity is so, the following code checks the distance between the 2 words and see if they should be together and if so \n",
    "    # it return with the entire phrase as a entity \n",
    "    runningPositionValuesCount = 0 \n",
    "    for numb in range(len(positionValuesEnitiesList)-1):\n",
    "        distancebetween = 0\n",
    "        lenWord = len(positionValuesEnitiesList[numb][0])\n",
    "        wordPosition = positionValuesEnitiesList[numb][2]\n",
    "        distancebetween =((positionValuesEnitiesList[numb+1][2] - (wordPosition + lenWord)))\n",
    "        sameElement = True if positionValuesEnitiesList[numb][1] == positionValuesEnitiesList[numb+1][1] else False\n",
    "        #print(sameElement)\n",
    "        if distancebetween < 2.5 and sameElement: # 2.5 is distance\n",
    "            #print(positionValuesEnitiesList[numb])\n",
    "            returnArray = [text_content[positionValuesEnitiesList[numb][2]:positionValuesEnitiesList[numb+1][2]+len(positionValuesEnitiesList[numb+1][1])]]\n",
    "            returnArray.append(positionValuesEnitiesList[numb][1])\n",
    "            finalArray.append(returnArray)\n",
    "        else: \n",
    "            finalArray.append([positionValuesEnitiesList[numb][0], positionValuesEnitiesList[numb][1]])\n",
    "    #print(distancebetween)\n",
    "    #if distancebetween/len(positionValuesEnitiesList)-1 < 2.5:\n",
    "        #returnArray = [text_content[positionValuesEnitiesList[0][2]:positionValuesEnitiesList[-1][2]+len(positionValuesEnitiesList[-1][1])]]\n",
    "        #returnArray.append(positionValuesEnitiesList[0][1])\n",
    "        #print(returnArray)\n",
    "    return finalArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run everything above \n",
    "sentenceArrayWithEntities = []\n",
    "for i in sentenceList:\n",
    "    temparray = []\n",
    "    temparray.append(i)\n",
    "    entityArray = extractEntities(i)\n",
    "    for j in entityArray:\n",
    "        temparray.extend(j)\n",
    "    sentenceArrayWithEntities.append(temparray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['team', 0.053995128720998764]]\n"
     ]
    }
   ],
   "source": [
    "importantEntitiesArray = extractMajorEntities(runningTextFINAL, 0.05)\n",
    "print(importantEntitiesArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check what document is about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_classify_text(text_content):\n",
    "    keyDIR = nlpAutoAPIPath # same as before api credentials\n",
    "    credentials = service_account.Credentials.from_service_account_file(keyDIR) # same as before\n",
    "    client = language_v1.LanguageServiceClient(credentials=credentials)\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "    language = \"en\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "    response = client.classify_text(document)\n",
    "    # Loop through classified categories returned from the API\n",
    "    categoryList = []\n",
    "    # this api returns what category the entire document is about and see what it really means\n",
    "    for category in response.categories:\n",
    "        # Get the name of the category representing the document.\n",
    "        # See the predefined taxonomy of categories:\n",
    "        # https://cloud.google.com/natural-language/docs/categories\n",
    "        # print(u\"Category name: {}\".format(category.name))\n",
    "        categoryList.append([category.name, category.confidence])\n",
    "    return categoryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Document is about: \u001b[1m/Finance/Accounting & Auditing\u001b[0m \t with a \u001b[1m95.0\u001b[0m accuracy.\n",
      "\n",
      "The Document is about: \u001b[1m/Business & Industrial\u001b[0m \t with a \u001b[1m55.0\u001b[0m accuracy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "allPossibleCategory = sample_classify_text(runningTextFINAL)\n",
    "for category in allPossibleCategory:\n",
    "    print((\"The Document is about: \" + '\\033[1m' + category[0] + '\\033[0m' + \n",
    "           \" \\t with a \" + '\\033[1m' + \"{:.1f}\"+ '\\033[0m' + \" accuracy.\\n\").format(category[1]*100))\n",
    "#print(allPossibleCategory)\n",
    "# print in a bold way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Sentences and Entities|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(excelFilesPath)\n",
    "# saved what was created in the excel folder place but with the following name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sentenceArrayWithEntities)\n",
    "EXCELFILENAMESent = documentRun[:-4] + \"_sentencesNew.xlsx\"\n",
    "df.to_excel(EXCELFILENAMESent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Document_118_sentencesNew.xlsx'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXCELFILENAMESent\n",
    "# name of the file with the sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- HUMAN MUST MANUALLY INPUT ENTITIES ---\n",
    "**CHECK THIS LINK FOR MORE INSTRUCTIONS**\n",
    "\n",
    "https://docs.google.com/document/d/1BdbWL7ePGPYiSVa07g8Erknwm_Zmi2JUwp588vJdUug/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Array to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCELFILENAMESent = documentRun[:-4] + \"_sentencesNew.xlsx\"\n",
    "# reads the excel name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCELFILENAMESent = '/Users/kunal/Documents/VdartResumeProject/ExcelFiles/OtherRun/Document_115_sentencesNew.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXCELFILENAMESent = 'Document_119_sentencesNew.xlsx'\n",
    "# if you want to call a sperate name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Excel and Turn into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(excelFilesPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.ExcelFile(EXCELFILENAMESent)\n",
    "totalTextRunning = runningTextFINAL\n",
    "attributes = text.parse(\"Sheet1\") \n",
    "# read excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>SCOTT JOHNSON</td>\n",
       "      <td>Name</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Cumming, GA ·</td>\n",
       "      <td>Address</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(937) 903-6163</td>\n",
       "      <td>Phone</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>johnsons71@yahoo.com ·</td>\n",
       "      <td>Email</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>As an</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>environment, I am seeking a position with a co...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>problem-solving and analytical skills as well ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>advanced accounting concepts.</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>&lt;perienced and detailed team accountant in a m...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>EXPERIENCE</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>03/2014 - 09/2019</td>\n",
       "      <td>Date</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11/2009 - 10/2011</td>\n",
       "      <td>Date</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>SR. OPERATIONAL AND ACCOUNTING CONSULTANT,</td>\n",
       "      <td>WorkExperience</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>METLIFE RETIREMENT &amp; INCOME SOLUTIONS</td>\n",
       "      <td>Company</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Cash account reconciliations - reconciled twen...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>accounts across five business groups (Stable V...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Paper, Structured Settlements, Income Annuitie...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Accounts, Pensions Direct Payment) daily to en...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>incoming/outgoing payments cleared and account...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>properly</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Suspense/clearing account reconciliations - re...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>suspense/clearing accounts to ensure accountin...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>properly for premium/benefits accounts</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Manual journal entries - cash and suspense rec...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>adjusting, closing</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Lockbox/Wire/ACH Monitoring - Chase Bank and W...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>liaison to resolve all premium issues for Inco...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Structured Settlements with Operations team in...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Month end reporting for US Controllers/Reserve...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>dollar transaction with US Controllers to conf...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>proper periods due to system limitations; addi...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Reserves to confirm reserve values are accurate</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Audit Requests - Internal and external pertain...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>SSAE 16 audits</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>System Training/Testing Custom web-based appli...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>training on accounting rules and premium proce...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>deployments of new business groups on this pla...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Training - trained three new associates on dut...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Tampa, Florida, from initial receipt of funds ...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>System Application Owner - System access \"Gate...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>audit; approved access, system access issues, ...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>Worked with various internal teams to help sup...</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>function for discrepancies/accounting failures</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>06/2006 - 11/2008</td>\n",
       "      <td>Date</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>SINCLAIR COMMUNITY COLLEGE, DAYTON, OHIO</td>\n",
       "      <td>Education</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>SKILLS</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Microsoft Suite</td>\n",
       "      <td>Skill</td>\n",
       "      <td>Software</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>(Excel/Word/Outlook/OneDrive)</td>\n",
       "      <td>Skill</td>\n",
       "      <td>MSOffice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>TrinTech ReconNet</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>ViTech custom web-based</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>administration system</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>PeopleSoft (general and sub-ledger)</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>Wells Fargo Lockbox Portal</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>Four custom Mainframe</td>\n",
       "      <td>Skill</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text               1  \\\n",
       "0                                       SCOTT JOHNSON            Name   \n",
       "1                                       Cumming, GA ·         Address   \n",
       "2                                      (937) 903-6163           Phone   \n",
       "3                              johnsons71@yahoo.com ·           Email   \n",
       "4                                               As an            None   \n",
       "5   environment, I am seeking a position with a co...            None   \n",
       "6   problem-solving and analytical skills as well ...            None   \n",
       "7                       advanced accounting concepts.            None   \n",
       "8   <perienced and detailed team accountant in a m...            None   \n",
       "9                                          EXPERIENCE            None   \n",
       "10                                  03/2014 - 09/2019            Date   \n",
       "11                                  11/2009 - 10/2011            Date   \n",
       "12         SR. OPERATIONAL AND ACCOUNTING CONSULTANT,  WorkExperience   \n",
       "13              METLIFE RETIREMENT & INCOME SOLUTIONS         Company   \n",
       "14  Cash account reconciliations - reconciled twen...           Skill   \n",
       "15  accounts across five business groups (Stable V...           Skill   \n",
       "16  Paper, Structured Settlements, Income Annuitie...           Skill   \n",
       "17  Accounts, Pensions Direct Payment) daily to en...           Skill   \n",
       "18  incoming/outgoing payments cleared and account...           Skill   \n",
       "19                                           properly           Skill   \n",
       "20  Suspense/clearing account reconciliations - re...           Skill   \n",
       "21  suspense/clearing accounts to ensure accountin...           Skill   \n",
       "22             properly for premium/benefits accounts           Skill   \n",
       "23  Manual journal entries - cash and suspense rec...           Skill   \n",
       "24                                 adjusting, closing           Skill   \n",
       "25  Lockbox/Wire/ACH Monitoring - Chase Bank and W...           Skill   \n",
       "26  liaison to resolve all premium issues for Inco...           Skill   \n",
       "27  Structured Settlements with Operations team in...           Skill   \n",
       "28  Month end reporting for US Controllers/Reserve...           Skill   \n",
       "29  dollar transaction with US Controllers to conf...           Skill   \n",
       "30  proper periods due to system limitations; addi...           Skill   \n",
       "31    Reserves to confirm reserve values are accurate           Skill   \n",
       "32  Audit Requests - Internal and external pertain...           Skill   \n",
       "33                                     SSAE 16 audits           Skill   \n",
       "34  System Training/Testing Custom web-based appli...           Skill   \n",
       "35  training on accounting rules and premium proce...           Skill   \n",
       "36  deployments of new business groups on this pla...           Skill   \n",
       "37  Training - trained three new associates on dut...           Skill   \n",
       "38  Tampa, Florida, from initial receipt of funds ...           Skill   \n",
       "39  System Application Owner - System access \"Gate...           Skill   \n",
       "40  audit; approved access, system access issues, ...           Skill   \n",
       "41  Worked with various internal teams to help sup...           Skill   \n",
       "42     function for discrepancies/accounting failures           Skill   \n",
       "43                                          EDUCATION            None   \n",
       "44                                  06/2006 - 11/2008            Date   \n",
       "45           SINCLAIR COMMUNITY COLLEGE, DAYTON, OHIO       Education   \n",
       "46                                             SKILLS            None   \n",
       "47                                    Microsoft Suite           Skill   \n",
       "48                      (Excel/Word/Outlook/OneDrive)           Skill   \n",
       "49                                  TrinTech ReconNet           Skill   \n",
       "50                            ViTech custom web-based           Skill   \n",
       "51                              administration system           Skill   \n",
       "52                PeopleSoft (general and sub-ledger)           Skill   \n",
       "53                         Wells Fargo Lockbox Portal           Skill   \n",
       "54                              Four custom Mainframe           Skill   \n",
       "\n",
       "           2   3   4   5   6  \n",
       "0        All NaN NaN NaN NaN  \n",
       "1        All NaN NaN NaN NaN  \n",
       "2        All NaN NaN NaN NaN  \n",
       "3        All NaN NaN NaN NaN  \n",
       "4        NaN NaN NaN NaN NaN  \n",
       "5        NaN NaN NaN NaN NaN  \n",
       "6        NaN NaN NaN NaN NaN  \n",
       "7        NaN NaN NaN NaN NaN  \n",
       "8        NaN NaN NaN NaN NaN  \n",
       "9        NaN NaN NaN NaN NaN  \n",
       "10       All NaN NaN NaN NaN  \n",
       "11       All NaN NaN NaN NaN  \n",
       "12       All NaN NaN NaN NaN  \n",
       "13       All NaN NaN NaN NaN  \n",
       "14       All NaN NaN NaN NaN  \n",
       "15       All NaN NaN NaN NaN  \n",
       "16       All NaN NaN NaN NaN  \n",
       "17       All NaN NaN NaN NaN  \n",
       "18       All NaN NaN NaN NaN  \n",
       "19       All NaN NaN NaN NaN  \n",
       "20       All NaN NaN NaN NaN  \n",
       "21       All NaN NaN NaN NaN  \n",
       "22       All NaN NaN NaN NaN  \n",
       "23       All NaN NaN NaN NaN  \n",
       "24       All NaN NaN NaN NaN  \n",
       "25       All NaN NaN NaN NaN  \n",
       "26       All NaN NaN NaN NaN  \n",
       "27       All NaN NaN NaN NaN  \n",
       "28       All NaN NaN NaN NaN  \n",
       "29       All NaN NaN NaN NaN  \n",
       "30       All NaN NaN NaN NaN  \n",
       "31       All NaN NaN NaN NaN  \n",
       "32       All NaN NaN NaN NaN  \n",
       "33       All NaN NaN NaN NaN  \n",
       "34       All NaN NaN NaN NaN  \n",
       "35       All NaN NaN NaN NaN  \n",
       "36       All NaN NaN NaN NaN  \n",
       "37       All NaN NaN NaN NaN  \n",
       "38       All NaN NaN NaN NaN  \n",
       "39       All NaN NaN NaN NaN  \n",
       "40       All NaN NaN NaN NaN  \n",
       "41       All NaN NaN NaN NaN  \n",
       "42       All NaN NaN NaN NaN  \n",
       "43       NaN NaN NaN NaN NaN  \n",
       "44       All NaN NaN NaN NaN  \n",
       "45       All NaN NaN NaN NaN  \n",
       "46       NaN NaN NaN NaN NaN  \n",
       "47  Software NaN NaN NaN NaN  \n",
       "48  MSOffice NaN NaN NaN NaN  \n",
       "49       All NaN NaN NaN NaN  \n",
       "50       All NaN NaN NaN NaN  \n",
       "51       All NaN NaN NaN NaN  \n",
       "52       All NaN NaN NaN NaN  \n",
       "53       All NaN NaN NaN NaN  \n",
       "54       All NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes\n",
    "# this is a table of all of the entities. \n",
    "# IMPORTANT -- the name of the first row with the text must be named \"Text\"\n",
    "# could be every how long columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "RowList = attributes.values.tolist()\n",
    "attributeList = [[i for i in row if isinstance(i,str)] for row in RowList]\n",
    "#Converts to a 2d array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Final List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_2_word(sentence):\n",
    "    # this functuion takes a sentence and splits it into each word and returns a list of all the words\n",
    "    word = \"\"\n",
    "    listofWords = []\n",
    "    for i in sentence:\n",
    "        if not (i == \" \" or i == \"\\n\"):\n",
    "            word += i \n",
    "        else:\n",
    "            listofWords.append(word)\n",
    "            word = \"\"\n",
    "    if len(listofWords) == 0:\n",
    "        listofWords.append(sentence)\n",
    "    return listofWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_indexes(input_str, search_str):\n",
    "    # find all the positions of where a text is in a string\n",
    "    # not used so dont worry\n",
    "    l1 = []\n",
    "    length = len(input_str)\n",
    "    index = 0\n",
    "    while index < length:\n",
    "        i = input_str.find(search_str, index)\n",
    "        if i == -1:\n",
    "            return l1\n",
    "        l1.append(i)\n",
    "        index = i + 1\n",
    "    return l1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNotWorkingValues(textFindPosition, totalTextRunning):\n",
    "    # if the find function cant find the text in the total text then this function splits the search text into each word \n",
    "    # find its value out of the entire text and if they are close enough then then it returns the position of the starting \n",
    "    # word of the search text but if it can't get a definitie answer then it returns -1 \n",
    "    words = textFindPosition.split()\n",
    "    wordPositions = []\n",
    "    for singleWord in words:\n",
    "        wordPositions.append(totalTextRunning.find(singleWord))\n",
    "    positionsCount = 0\n",
    "    numCorrect = 0\n",
    "    for num in range(len(wordPositions)-1):\n",
    "        if wordPositions[num]+len(words[num])+1 == wordPositions[num+1]:\n",
    "            numCorrect+=1\n",
    "        positionsCount+=1\n",
    "    if numCorrect == len(words)-1:\n",
    "        return wordPositions[0]\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNotWorkingValues(textFindPosition, totalTextRunning):\n",
    "    words = textFindPosition.split()\n",
    "    if len(words) >= 7:\n",
    "        wordListNew = []\n",
    "        for number in range(1, len(words), 2):\n",
    "            wordListNew.append(words[number-1] + \" \" + words[number])\n",
    "        if not len(words) % 2 == 0: \n",
    "            wordListNew.append(words[-1])\n",
    "        #print(wordListNew)\n",
    "    words = wordListNew\n",
    "    wordPositions = []\n",
    "    numberstarting = 0  \n",
    "    for singleWord in words:\n",
    "        #print(totalTextRunning[numberstarting:].find(singleWord))\n",
    "        wordPositions.append(totalTextRunning[numberstarting:].find(singleWord)+numberstarting)\n",
    "        if not totalTextRunning[numberstarting:].find(singleWord) == -1:\n",
    "            numberstarting = totalTextRunning[numberstarting:].find(singleWord) +numberstarting\n",
    "        #print(numberstarting)    \n",
    "    #print(wordPositions)\n",
    "    positionsCount = 0\n",
    "    numCorrect = 0\n",
    "    for num in range(len(wordPositions)-1):\n",
    "        if abs(wordPositions[num]+len(words[num])+1 - wordPositions[num+1]) < 2:\n",
    "            numCorrect+=1\n",
    "        #else:\n",
    "            #print(words[num])\n",
    "            #print(wordPositions[num])\n",
    "            #print(len(words[num])+1)\n",
    "            #print(wordPositions[num]+len(words[num])+1)\n",
    "            #print(wordPositions[num+1])\n",
    "            #print(\"\")\n",
    "        positionsCount+=1\n",
    "    #print(positionsCount)\n",
    "    #print(numCorrect)\n",
    "    if numCorrect/positionsCount > 0.6:\n",
    "        return wordPositions[0]\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL OF \u001b[1m55\u001b[0m entities detected\n"
     ]
    }
   ],
   "source": [
    "possibleEntitiyNames = [\"Skill\", \"Company\", \"WorkExperience\", \"Name\", \"Address\", \"Phone\", \"Email\", \"Date\", \"Link\", \n",
    "                        \"Education\", \"Software\", \"Hardware\", \"AwardCertification\", \"None\"]\n",
    "numbAttributeReal = 0\n",
    "lineCount = 2\n",
    "entitiesperLine = []\n",
    "for line in attributeList:\n",
    "    if len(line) == 2 and not line[1] == \"None\":\n",
    "        print(\"SENTENCE LEFT BLANK \\t ERROR IN DATA! Check line \\033[1m\" + str(lineCount) + \n",
    "              \"\\033[0m. The sentence is \\033[1m\"+ line[0] + \"\\033[0m with entity of \\033[1m\" + \n",
    "              line [1] + \"\\033[0m\")\n",
    "        #break\n",
    "    if len(line) == 0:\n",
    "        print(\"LINE IS BLANK \\t ERROR IN DATA!\\t Check line \\033[1m\" + str(lineCount) + \"\\033[0m.\")\n",
    "    if len(line) > 2 and len(line) % 2 == 0:\n",
    "        print(\"ENTITIES NOT COMPLETED ERROR IN DATA!\\t Check line \\033[1m\" + str(lineCount) + \"\\033[0m.\")\n",
    "        print(line)\n",
    "    if not line[1] in possibleEntitiyNames:\n",
    "        print(\"ENTITIES INVALID ERROR IN DATA!\\t Check line \\033[1m\" + str(lineCount) + \"\\033[0m. Entity name is: \\033[1m\" +\n",
    "             line[1] + \"\\033[0m.\")\n",
    "        print(line)\n",
    "    #print(len(line))\n",
    "    entitiesperLine.append(int((len(line)-1)/2))\n",
    "    #1if not len(line) == 2:\n",
    "    lineCount += 1\n",
    "print(\"TOTAL OF \\033[1m\" + str(len(entitiesperLine)) + \"\\033[0m entities detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT DETECTED\n",
      "['Microsoft Suite', 'Skill', 'Software']\n",
      "NOT DETECTED\n",
      "['(Excel/Word/Outlook/OneDrive)', 'Skill', 'MSOffice']\n"
     ]
    }
   ],
   "source": [
    "attributesNumberList = []\n",
    "for j in attributeList:\n",
    "    runningAttributeNum = []\n",
    "    if len(j) == 2:\n",
    "        continue\n",
    "    if j[2] == \"All\": \n",
    "        startChar = totalTextRunning.find(j[0].strip())\n",
    "        if startChar == -1:\n",
    "            words = j[0].strip().split()\n",
    "            if len(words) >= 7:\n",
    "                wordListNew = []\n",
    "                for number in range(1, len(words), 2):\n",
    "                    wordListNew.append(words[number-1] + \" \" + words[number])\n",
    "                if not len(words) % 2 == 0: \n",
    "                    wordListNew.append(words[-1])\n",
    "                words = wordListNew\n",
    "            wordPositions = []\n",
    "            numberstarting = 0  \n",
    "            for singleWord in words:\n",
    "                wordPositions.append(totalTextRunning[numberstarting:].find(singleWord)+numberstarting)\n",
    "                if not totalTextRunning[numberstarting:].find(singleWord) == -1:\n",
    "                    numberstarting = totalTextRunning[numberstarting:].find(singleWord) +numberstarting\n",
    "            positionsCount = 0\n",
    "            numCorrect = 0\n",
    "            for num in range(len(wordPositions)-1):\n",
    "                if abs(wordPositions[num]+len(words[num])+1 - wordPositions[num+1]) < 2:\n",
    "                    numCorrect+=1\n",
    "                positionsCount+=1\n",
    "            try: \n",
    "                if numCorrect/positionsCount > 0.6:\n",
    "                    startChar = wordPositions[0]\n",
    "                else:\n",
    "                    startChar = -1  \n",
    "            except ZeroDivisionError:\n",
    "                startChar = -1 \n",
    "        if startChar == -1:\n",
    "            # lower everything and see if it can find it then\n",
    "            startChar = totalTextRunning.lower().find(j[0].lower().strip())\n",
    "        endChar = startChar + len(j[0].strip())\n",
    "        runningAttributeNum.extend([j[1].strip().upper() , startChar, endChar])\n",
    "        #print(j[1].strip().upper() + \"\\t\" + totalTextRunning[startChar: endChar])\n",
    "        attributesNumberList.append(runningAttributeNum)\n",
    "        # print(runningAttributeNum)\n",
    "    else:\n",
    "        #print(\"RUNNING \" + str(int((len(j)-1)/2)))\n",
    "        # im not going to go in detail explaining this but copy this function into a sepreate file and try it out\n",
    "        # similar to the \"all thing\" but it works for any number of attributes \n",
    "        for w in range(0, int((len(j)-1)), 2):\n",
    "            runningAttributeNum = []\n",
    "            if not totalTextRunning.find(j[2+w]) == -1:\n",
    "                startChar = totalTextRunning.find(j[2+w].strip())\n",
    "                if startChar == -1:\n",
    "                    startChar = checkNotWorkingValues(j[2+w].strip(), totalTextRunning)\n",
    "                if startChar == -1:\n",
    "                    startChar = totalTextRunning.lower().find(j[2+w].lower().strip())\n",
    "                endChar = startChar + len(j[2+w])\n",
    "                runningAttributeNum.extend([j[1+w].upper(), startChar, endChar])\n",
    "                #print(\"--\"  + j[1].strip().upper() + \"\\t\" + totalTextRunning[startChar: endChar])\n",
    "            else:\n",
    "                word = \"\"\n",
    "                listofWords = []\n",
    "                for i in j[2+w]:\n",
    "                    if not (i == \" \" or i == \"\\n\"):\n",
    "                        word += i \n",
    "                    else:\n",
    "                        listofWords.append(word)\n",
    "                        word = \"\"\n",
    "                listofWords.append(word)\n",
    "                if len(listofWords) == 0:\n",
    "                    listofWords.append(j[2+w])           \n",
    "                words = listofWords\n",
    "                detected = 0\n",
    "                position = []\n",
    "                for g in words:\n",
    "                    if not j[2+w].find(g) == -1:\n",
    "                        #charTemp = j[2+w].find(g)\n",
    "                        detected+=1\n",
    "                        position.append(j[2+w].find(g))\n",
    "                correct = 0\n",
    "                allcount = 0\n",
    "                for thing in range(len(position)-1):\n",
    "                    if abs(position[thing] + len(words[thing]) - position[thing+1]) < 2:\n",
    "                        correct+=1\n",
    "                    allcount+=1\n",
    "                if correct >= 1:\n",
    "                    u = words\n",
    "                    counter2 = 0\n",
    "                    connectedProbability = []\n",
    "                    for numb in range(len(u)-1):\n",
    "                        #print(u[numb])\n",
    "                        indexArray  = find_all_indexes(totalTextRunning, u[numb])\n",
    "                        uptadedArray = []\n",
    "                        for i in indexArray:\n",
    "                            uptadedArray.append(i+len(u[numb]))\n",
    "                        indexArrayWord2 = find_all_indexes(totalTextRunning, u[numb+1])\n",
    "                        #print(indexArrayWord2)\n",
    "                        for number2 in indexArrayWord2:\n",
    "                            try:\n",
    "                                whichNumbClosest = indexArray[min(range(len(indexArray)), key = lambda i: abs(indexArray[i]-number2))]\n",
    "                            except ValueError:\n",
    "                                pass\n",
    "                            #print([whichNumbClosest, number2-1])\n",
    "                            connectedProbability.append([whichNumbClosest, number2-1])\n",
    "                            #if number2 > whichNumbClosest and abs((number2-whichNumbClosest)-len(u[numb])) < 3:\n",
    "                                #connectedProbability.append([whichNumbClosest, number2-1])\n",
    "                            #else:\n",
    "                                #connectedProbability.append([whichNumbClosest, number2-1])\n",
    "                    startChar = connectedProbability[0][0]\n",
    "                    endChar = startChar + len(j[2+w])\n",
    "                    runningAttributeNum.extend([words[0].upper(), startChar, endChar])\n",
    "                else:\n",
    "                    charTemp = -1 # couldn't finf anything\n",
    "                    print(\"NOT DETECTED\")\n",
    "                    endChar = -1\n",
    "                    startChar = -1\n",
    "                    runningAttributeNum.extend([\"NOTDETECTED\", startChar, endChar])\n",
    "                #print(j[1].strip().upper() + \"\\t\" + totalTextRunning[startChar: endChar])\n",
    "            attributesNumberList.append(runningAttributeNum)\n",
    "    if startChar == -1:\n",
    "        print(j )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attributesNumberList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NAME', 0, 13],\n",
       " ['ADDRESS', 14, 27],\n",
       " ['PHONE', 27, 41],\n",
       " ['EMAIL', 44, 66],\n",
       " ['DATE', 313, 330],\n",
       " ['DATE', 331, 348],\n",
       " ['WORKEXPERIENCE', 349, 391],\n",
       " ['COMPANY', 392, 429],\n",
       " ['SKILL', 430, 487],\n",
       " ['SKILL', 488, 549],\n",
       " ['SKILL', 550, 607],\n",
       " ['SKILL', 608, 658],\n",
       " ['SKILL', 659, 718],\n",
       " ['SKILL', 719, 727],\n",
       " ['SKILL', 728, 789],\n",
       " ['SKILL', 790, 847],\n",
       " ['SKILL', 848, 886],\n",
       " ['SKILL', 887, 947],\n",
       " ['SKILL', 948, 966],\n",
       " ['SKILL', 967, 1028],\n",
       " ['SKILL', 1029, 1091],\n",
       " ['SKILL', 1092, 1144],\n",
       " ['SKILL', 1145, 1208],\n",
       " ['SKILL', 1209, 1274],\n",
       " ['SKILL', 1275, 1341],\n",
       " ['SKILL', 1342, 1389],\n",
       " ['SKILL', 1390, 1450],\n",
       " ['SKILL', 1451, 1465],\n",
       " ['SKILL', 1466, 1520],\n",
       " ['SKILL', 1521, 1585],\n",
       " ['SKILL', 1586, 1637],\n",
       " ['SKILL', 1638, 1703],\n",
       " ['SKILL', 1704, 1767],\n",
       " ['SKILL', 1768, 1825],\n",
       " ['SKILL', 1826, 1880],\n",
       " ['SKILL', 1881, 1942],\n",
       " ['SKILL', 1943, 1989],\n",
       " ['DATE', 2000, 2017],\n",
       " ['EDUCATION', 2018, 2058],\n",
       " ['NOTDETECTED', -1, -1],\n",
       " ['NOTDETECTED', -1, -1],\n",
       " ['SKILL', 2112, 2129],\n",
       " ['SKILL', 2130, 2153],\n",
       " ['SKILL', 2154, 2175],\n",
       " ['SKILL', 2176, 2211],\n",
       " ['SKILL', 2212, 2238],\n",
       " ['SKILL', 2239, 2260]]"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributesNumberList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attributesNumberList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOTDETECTED', -1, -1]\n"
     ]
    }
   ],
   "source": [
    "for testing in attributesNumberList:\n",
    "    # if it can't find it removes it \n",
    "    if testing[1] == -1:\n",
    "        print(testing)\n",
    "        attributesNumberList.remove(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet to JSON FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attributesNumberList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributeCount = len(attributesNumberList)\n",
    "text = totalTextRunning\n",
    "attributes = attributesNumberList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SCOTT JOHNSON\\nCumming, GA ·(937) 903-6163\\n• johnsons71@yahoo.com ·\\nAs an\\nenvironment, I am seeking a position with a company that will utilize my\\nproblem-solving and analytical skills as well as my understanding of\\nadvanced accounting concepts.\\n<perienced and detailed team accountant in a multi-group\\nEXPERIENCE\\n03/2014 - 09/2019\\n11/2009 - 10/2011\\nSR. OPERATIONAL AND ACCOUNTING CONSULTANT, METLIFE\\nRETIREMENT & INCOME SOLUTIONS\\nCash account reconciliations - reconciled twenty-one cash\\naccounts across five business groups (Stable Value/Commercial\\nPaper, Structured Settlements, Income Annuities, Separate\\nAccounts, Pensions Direct Payment) daily to ensure\\nincoming/outgoing payments cleared and accounting generated\\nproperly\\nSuspense/clearing account reconciliations - reconciled twelve\\nsuspense/clearing accounts to ensure accounting generated\\nproperly for premium/benefits accounts\\nManual journal entries - cash and suspense reclass, accrual,\\nadjusting, closing\\nLockbox/Wire/ACH Monitoring - Chase Bank and Wells Fargo - US\\nliaison to resolve all premium issues for Income Annuities and\\nStructured Settlements with Operations team in India\\nMonth end reporting for US Controllers/Reserves - reviewed high\\ndollar transaction with US Controllers to confirm reporting is in\\nproper periods due to system limitations; additional reporting for\\nReserves to confirm reserve values are accurate\\nAudit Requests - Internal and external pertaining to SOX and\\nSSAE 16 audits\\nSystem Training/Testing Custom web-based application -\\ntraining on accounting rules and premium processing, testing for\\ndeployments of new business groups on this platform\\nTraining - trained three new associates on duties transferring to\\nTampa, Florida, from initial receipt of funds to reconciliation\\nSystem Application Owner - System access \"Gatekeeper\" for\\naudit; approved access, system access issues, internal\\nWorked with various internal teams to help support accounting\\nfunction for discrepancies/accounting failures\\nEDUCATION\\n06/2006 - 11/2008\\nSINCLAIR COMMUNITY COLLEGE, DAYTON, OHIO\\nSKILLS\\nMicrosoft Suite\\n(Excel/Word/Outlook/OneDrive)\\nTrinTech ReconNet\\nViTech custom web-based\\nadministration system\\nPeopleSoft (general and sub-ledger)\\nWells Fargo Lockbox Portal\\nFour custom Mainframe'"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createJSONFILE(attributeCount, text, attributes):\n",
    "    #the 2 string named \"totalString\" and \"attributeString\" are just formated in a way how google likes their input value\n",
    "    # loops through everything and uses the replace function to replace it with all the attributes\n",
    "    # you have to test this out yourself to understand how it works\n",
    "    alphab = list(string.ascii_lowercase)\n",
    "    for alpa in range(int(attributeCount/26)):\n",
    "        alphab.extend(list(string.ascii_lowercase))\n",
    "    totalString = \"\"\"{\"textSnippet\":{\"content\":\"textCODE\"},\"annotations\":[attributeCODE]}\"\"\"\n",
    "    attributeString = \"\"\"{\"displayName\":\"AtribnameCODE\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"sCharCODE\",\"endOffset\":\"eCharCODE\"}}}\"\"\"\n",
    "    totalString =  totalString.replace(\"textCODE\", text)\n",
    "    tempStringReplacer = \"\"\n",
    "    for i in range(attributeCount):\n",
    "        if i != attributeCount-1:\n",
    "            tempStringReplacer+=(\"atriCODE\"+str(i+1)+alphab[i]+\",\")\n",
    "        else:\n",
    "            tempStringReplacer+=(\"atriCODE\"+str(i+1)+alphab[i])\n",
    "    totalString = totalString.replace(\"attributeCODE\", tempStringReplacer)\n",
    "    for i in range(attributeCount):\n",
    "        attributeStringNEW = attributeString\n",
    "        #print(attributes[i])\n",
    "        attributeStringNEW = attributeStringNEW.replace(\"AtribnameCODE\", attributes[i][0])\n",
    "        attributeStringNEW = attributeStringNEW.replace(\"sCharCODE\", str(attributes[i][1])).replace(\"eCharCODE\", str(attributes[i][2]))\n",
    "        totalString = totalString.replace((\"atriCODE\"+str(i+1)+alphab[i]), attributeStringNEW)\n",
    "    return totalString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Run Create JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = createJSONFILE(attributeCount, text, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributeCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"textSnippet\":{\"content\":\"SCOTT JOHNSON\\nCumming, GA ·(937) 903-6163\\n• johnsons71@yahoo.com ·\\nAs an\\nenvironment, I am seeking a position with a company that will utilize my\\nproblem-solving and analytical skills as well as my understanding of\\nadvanced accounting concepts.\\n<perienced and detailed team accountant in a multi-group\\nEXPERIENCE\\n03/2014 - 09/2019\\n11/2009 - 10/2011\\nSR. OPERATIONAL AND ACCOUNTING CONSULTANT, METLIFE\\nRETIREMENT & INCOME SOLUTIONS\\nCash account reconciliations - reconciled twenty-one cash\\naccounts across five business groups (Stable Value/Commercial\\nPaper, Structured Settlements, Income Annuities, Separate\\nAccounts, Pensions Direct Payment) daily to ensure\\nincoming/outgoing payments cleared and accounting generated\\nproperly\\nSuspense/clearing account reconciliations - reconciled twelve\\nsuspense/clearing accounts to ensure accounting generated\\nproperly for premium/benefits accounts\\nManual journal entries - cash and suspense reclass, accrual,\\nadjusting, closing\\nLockbox/Wire/ACH Monitoring - Chase Bank and Wells Fargo - US\\nliaison to resolve all premium issues for Income Annuities and\\nStructured Settlements with Operations team in India\\nMonth end reporting for US Controllers/Reserves - reviewed high\\ndollar transaction with US Controllers to confirm reporting is in\\nproper periods due to system limitations; additional reporting for\\nReserves to confirm reserve values are accurate\\nAudit Requests - Internal and external pertaining to SOX and\\nSSAE 16 audits\\nSystem Training/Testing Custom web-based application -\\ntraining on accounting rules and premium processing, testing for\\ndeployments of new business groups on this platform\\nTraining - trained three new associates on duties transferring to\\nTampa, Florida, from initial receipt of funds to reconciliation\\nSystem Application Owner - System access \"Gatekeeper\" for\\naudit; approved access, system access issues, internal\\nWorked with various internal teams to help support accounting\\nfunction for discrepancies/accounting failures\\nEDUCATION\\n06/2006 - 11/2008\\nSINCLAIR COMMUNITY COLLEGE, DAYTON, OHIO\\nSKILLS\\nMicrosoft Suite\\n(Excel/Word/Outlook/OneDrive)\\nTrinTech ReconNet\\nViTech custom web-based\\nadministration system\\nPeopleSoft (general and sub-ledger)\\nWells Fargo Lockbox Portal\\nFour custom Mainframe\"},\"annotations\":[{\"displayName\":\"NAME\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"0\",\"endOffset\":\"13\"}}},{\"displayName\":\"ADDRESS\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"14\",\"endOffset\":\"27\"}}},{\"displayName\":\"PHONE\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"27\",\"endOffset\":\"41\"}}},{\"displayName\":\"EMAIL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"44\",\"endOffset\":\"66\"}}},{\"displayName\":\"DATE\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"313\",\"endOffset\":\"330\"}}},{\"displayName\":\"DATE\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"331\",\"endOffset\":\"348\"}}},{\"displayName\":\"WORKEXPERIENCE\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"349\",\"endOffset\":\"391\"}}},{\"displayName\":\"COMPANY\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"392\",\"endOffset\":\"429\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"430\",\"endOffset\":\"487\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"488\",\"endOffset\":\"549\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"550\",\"endOffset\":\"607\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"608\",\"endOffset\":\"658\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"659\",\"endOffset\":\"718\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"719\",\"endOffset\":\"727\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"728\",\"endOffset\":\"789\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"790\",\"endOffset\":\"847\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"848\",\"endOffset\":\"886\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"887\",\"endOffset\":\"947\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"948\",\"endOffset\":\"966\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"967\",\"endOffset\":\"1028\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1029\",\"endOffset\":\"1091\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1092\",\"endOffset\":\"1144\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1145\",\"endOffset\":\"1208\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1209\",\"endOffset\":\"1274\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1275\",\"endOffset\":\"1341\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1342\",\"endOffset\":\"1389\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1390\",\"endOffset\":\"1450\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1451\",\"endOffset\":\"1465\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1466\",\"endOffset\":\"1520\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1521\",\"endOffset\":\"1585\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1586\",\"endOffset\":\"1637\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1638\",\"endOffset\":\"1703\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1704\",\"endOffset\":\"1767\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1768\",\"endOffset\":\"1825\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1826\",\"endOffset\":\"1880\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1881\",\"endOffset\":\"1942\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"1943\",\"endOffset\":\"1989\"}}},{\"displayName\":\"DATE\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"2000\",\"endOffset\":\"2017\"}}},{\"displayName\":\"EDUCATION\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"2018\",\"endOffset\":\"2058\"}}},{\"displayName\":\"NOTDETECTED\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"-1\",\"endOffset\":\"-1\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"2112\",\"endOffset\":\"2129\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"2130\",\"endOffset\":\"2153\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"2154\",\"endOffset\":\"2175\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"2176\",\"endOffset\":\"2211\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"2212\",\"endOffset\":\"2238\"}}},{\"displayName\":\"SKILL\",\"textExtraction\":{\"textSegment\":{\"startOffset\":\"2239\",\"endOffset\":\"2260\"}}}]}'"
      ]
     },
     "execution_count": 809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save JSONL FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(jsonFolderPath)\n",
    "# open a file and save it \n",
    "jsonFileName = \"Final_New_\"+documentRun[9:-4]+\".jsonl\"\n",
    "with io.open(jsonFileName, \"w\", encoding=\"utf-8\") as text_file:\n",
    "    text_file.write(file)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final_New_115.jsonl\n"
     ]
    }
   ],
   "source": [
    "print(jsonFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(jsonFileName, \"r\")\n",
    "#print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your done and you have the Json file, give it to kunal and he will put it into GCP platform account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final_New_100.jsonl\n",
      "Final_New_105.jsonl\n",
      "Final_New_106.jsonl\n",
      "Final_New_108.jsonl\n",
      "Final_New_109.jsonl\n",
      "Final_New_112.jsonl\n",
      "Final_New_113.jsonl\n",
      "Final_New_115.jsonl\n",
      "Final_New_119.jsonl\n",
      "Final_New_122.jsonl\n",
      "Final_New_125.jsonl\n",
      "Final_New_139.jsonl\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "numFilecount = 0\n",
    "for i in os.listdir(jsonFolderPath):\n",
    "    if i.startswith(\"Final_New_\"):\n",
    "        print(i)\n",
    "        numFilecount+=1\n",
    "print(numFilecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('Final_New_108.jsonl', 'r')\n",
    "#file_contents = f.read()\n",
    "#print (file_contents)\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

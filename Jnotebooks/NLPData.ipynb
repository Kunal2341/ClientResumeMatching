{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "import ntpath\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import vision\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "from spacy.lang.en import English # updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF TO TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_2_image(uploaded_image_path, uploaded_image):\n",
    "    project_dir = os.getcwd()\n",
    "    os.chdir(uploaded_image_path)\n",
    "    file_name = str(uploaded_image).replace('.pdf','')\n",
    "    pages = convert_from_path(uploaded_image, 200,poppler_path='/Users/kunal/Documents/VdartWorking/Poppler/poppler-0.68.0_x86/poppler-0.68.0/bin/')\n",
    "    pageNumCount = 1\n",
    "    outputNames = []\n",
    "    for page in pages:\n",
    "        output_file = file_name+\"_\"+str(pageNumCount) + '.jpg'\n",
    "        page.save(output_file, 'JPEG')\n",
    "        pageNumCount +=1\n",
    "        outputNames.append(output_file)\n",
    "    return outputNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_2_text(imagePath):\n",
    "    keyDIR = \"/Users/kunal/Documents/ResumeNLPVdart/APIKEYSGOOGLE/resumeMatcher-pdf2img.json\"\n",
    "    credentials = service_account.Credentials.from_service_account_file(keyDIR)\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "    with io.open(imagePath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.types.Image(content=content)\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    totalString = ''\n",
    "    for text in texts:\n",
    "        totalString+=text.description\n",
    "    totalString = totalString.rsplit(' ', 1)[0]\n",
    "    return totalString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deleteIMG(path):\n",
    "    for i in os.listdir(path):\n",
    "        if i.endswith(\".jpg\"):\n",
    "            os.remove(folder_pdf + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_pdf = '/Users/kunal/Documents/ResumeNLPVdart/Testing_Delete/'\n",
    "#deleteIMG(folder_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Document_402_1.jpg']\n",
      "1\n",
      "['Document_403_1.jpg']\n",
      "1\n",
      "['Document_405_1.jpg', 'Document_405_2.jpg', 'Document_405_3.jpg', 'Document_405_4.jpg', 'Document_405_5.jpg', 'Document_405_6.jpg']\n",
      "6\n",
      "['Document_406_1.jpg', 'Document_406_2.jpg', 'Document_406_3.jpg', 'Document_406_4.jpg', 'Document_406_5.jpg']\n",
      "5\n",
      "['Document_407_1.jpg', 'Document_407_2.jpg', 'Document_407_3.jpg']\n",
      "3\n",
      "['Document_408_1.jpg', 'Document_408_2.jpg']\n",
      "2\n",
      "['Document_409_1.jpg', 'Document_409_2.jpg']\n",
      "2\n",
      "['Document_410_1.jpg', 'Document_410_2.jpg', 'Document_410_3.jpg', 'Document_410_4.jpg', 'Document_410_5.jpg', 'Document_410_6.jpg', 'Document_410_7.jpg', 'Document_410_8.jpg', 'Document_410_9.jpg', 'Document_410_10.jpg', 'Document_410_11.jpg']\n",
      "11\n",
      "['Document_411_1.jpg']\n",
      "1\n",
      "['Document_412_1.jpg', 'Document_412_2.jpg']\n",
      "2\n",
      "['Document_413_1.jpg', 'Document_413_2.jpg']\n",
      "2\n",
      "['Document_414_1.jpg']\n",
      "1\n",
      "['Document_415_1.jpg']\n",
      "1\n",
      "['Document_417_1.jpg', 'Document_417_2.jpg']\n",
      "2\n",
      "['Document_418_1.jpg', 'Document_418_2.jpg', 'Document_418_3.jpg']\n",
      "3\n",
      "['Document_419_1.jpg', 'Document_419_2.jpg']\n",
      "2\n",
      "['Document_420_1.jpg', 'Document_420_2.jpg']\n",
      "2\n",
      "['Document_421_1.jpg', 'Document_421_2.jpg', 'Document_421_3.jpg', 'Document_421_4.jpg', 'Document_421_5.jpg', 'Document_421_6.jpg', 'Document_421_7.jpg', 'Document_421_8.jpg', 'Document_421_9.jpg', 'Document_421_10.jpg']\n",
      "10\n",
      "['Document_422_1.jpg', 'Document_422_2.jpg', 'Document_422_3.jpg']\n",
      "3\n",
      "['Document_423_1.jpg', 'Document_423_2.jpg']\n",
      "2\n",
      "['Document_424_1.jpg', 'Document_424_2.jpg']\n",
      "2\n",
      "['Document_425_1.jpg', 'Document_425_2.jpg', 'Document_425_3.jpg']\n",
      "3\n",
      "['Document_426_1.jpg', 'Document_426_2.jpg']\n",
      "2\n",
      "['Document_427_1.jpg', 'Document_427_2.jpg', 'Document_427_3.jpg', 'Document_427_4.jpg', 'Document_427_5.jpg']\n",
      "5\n",
      "['Document_428_1.jpg', 'Document_428_2.jpg']\n",
      "2\n",
      "['Document_429_1.jpg', 'Document_429_2.jpg']\n",
      "2\n",
      "['Document_430_1.jpg', 'Document_430_2.jpg']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "textList = []\n",
    "numberPagesList = []\n",
    "folder_pdf = '/Users/kunal/Documents/ResumeNLPVdart/Testing_Delete/'\n",
    "for i in os.listdir(folder_pdf):\n",
    "    if os.path.exists(folder_pdf + i[:-4] + \".jpg\") == False:\n",
    "        if i.endswith(\".pdf\"):\n",
    "            imgName = convert_pdf_2_image(folder_pdf, i)\n",
    "            print(imgName)\n",
    "            print(len(imgName))\n",
    "    for q in range(len(imgName)):\n",
    "        text = convert_img_2_text(folder_pdf + i[:-4] + \"_\" + str(q+1) + \".jpg\")\n",
    "        textList.append(text)    \n",
    "        numberPagesList.append(len(imgName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() \n",
    "df['Text Extracted'] = textList\n",
    "df['DocumentNum'] = numberPagesList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/kunal/Documents/ResumeNLPVdart/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('alltextExtracted6.xlsx', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.ExcelFile(\"alltextExtracted6.xlsx\")\n",
    "dftext = text.parse(\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Extracted</th>\n",
       "      <th>DocumentNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NISARGA HASSAN SREEDHAR\\nSan Jose, California ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Rodolfo Cornel Jr.\\n13214 Fidler Ave. Downey, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Microsoft\\nCERTIFIED\\naws certified\\nProfessio...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Microsoft\\nCERTIFIED\\naws certified\\nProfessio...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Microsoft\\nCERTIFIED\\naws certified\\nProfessio...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Extracted  DocumentNum\n",
       "0  NISARGA HASSAN SREEDHAR\\nSan Jose, California ...            1\n",
       "1  Rodolfo Cornel Jr.\\n13214 Fidler Ave. Downey, ...            1\n",
       "2  Microsoft\\nCERTIFIED\\naws certified\\nProfessio...            6\n",
       "3  Microsoft\\nCERTIFIED\\naws certified\\nProfessio...            6\n",
       "4  Microsoft\\nCERTIFIED\\naws certified\\nProfessio...            6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = dftext[\"Text Extracted\"].tolist()\n",
    "pagesList = dftext[\"DocumentNum\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Recommendation letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EY\n",
      "Tel: +1 212 773 3000\n",
      "Ernst & Young LLP\n",
      "5 Times Square\n",
      "New York, NY 10036-6530\n",
      "Fax: +1 212 773 6350\n",
      "ey.com\n",
      "Building a better\n",
      "working world\n",
      "April 30, 2018\n",
      "Letter of Recommendation: Angelene Jean-Louis\n",
      "Angelene and I were paired together as mentor-mentee for the Fall 2014 semester through\n",
      "the Rutgers Business School (RBS) TeamUp mentoring program. The program provides RBS\n",
      "students with the opportunity to have a one-to-one mentorship experience for a semester with\n",
      "a business professional. The experience is intended to provide students, like Angelene, with\n",
      "insights about the nature of the profession of their interest and guidance on how to be a\n",
      "successful professional and future business leader.\n",
      "From the moment I met her, I was encouraged and energized by Angelene's eagerness to\n",
      "learn. We have kept in regular contact ever since, even after the one-semester program had\n",
      "ended. Aside from spending time on her studies, she has continued to balance raising a family\n",
      "and working full-time. During our discussions over the years, she has remained inquisitive,\n",
      "seeks to maintain awareness of current hot topics in the accounting/auditing industry, and\n",
      "learn about the challenges she will face when working in the accounting profession.\n",
      "Angelene's future is very bright and a firm that brings her onboard will be gaining a diligent,\n",
      "determined individual that will consistently add value to any organization she is a part of.\n",
      "If you have any questions, please feel free to reach out to me directly at 212-773-0168.\n",
      "Sincerely,\n",
      "Stephen A. Verrone\n",
      "Executive Director, Professional Practice Financial Services\n",
      "Ernst & Young LLP\n",
      "A member firm of Ernst & Young Global\n",
      "\n",
      "UNIVERSIDAD\n",
      "EAFIT\n",
      "August 20, 2019\n",
      "Subject: Recommendation for Angelene Jean-Louis\n",
      "To Whom it May Concern:\n",
      "It is my pleasure to recommend Ms. Angelene Jean-Louis for any scholarship or job for which she might\n",
      "apply. Angelene attended my Business Policy and Strategy class at the Business School of Rutgers\n",
      "University, New Jersey in Spring 2017. From the start, she stood out from her classmates with her hard\n",
      "work, astute comments, willing teamwork, and discussion-leadership. She always presented well-argued\n",
      "and articulated positions, yet tactfully acknowledged others' opinions that differed from her own. At the\n",
      "end of the course she delivered the best oral presentation of the class, and received a final grade of A\n",
      "within a school-mandated strict grading policy. Angelene is one of those students you will always\n",
      "remember. It was a joy to have her in my class, and I see a bright future ahead of her. She will be an\n",
      "outstanding candidate for any job or scholarship.\n",
      "If I can be of any further assistance, or provide you with more information, please do not hesitate\n",
      "to contact me.\n",
      "Yours sincerely,\n",
      "Andres Velez-Calle, Ph.D.\n",
      "Assistant Professor\n",
      "Universidad EAFIT\n",
      "avelezca@eafit.edu.co\n",
      "Carrera 49 No 7 Sur - 50\n",
      "Tel: +57 4 2619500 ext. 8673\n",
      "Universidad EAFIT\n",
      "Medellin, Colombia\n",
      "Fax: +574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in text_list:\n",
    "    if \"Recommendation\" in str(i): \n",
    "        print(i)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-127-ee05f2b841ec>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-127-ee05f2b841ec>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    CHECK FOR RECOMMENDATION\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "CHECK FOR RECOMMENDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalText = []\n",
    "for u in range(len(pagesList)):\n",
    "    textExtracted = \"\"\n",
    "    for h in range(pagesList[u]):\n",
    "        try:\n",
    "            textExtracted = textExtracted + \"\\n\" + text_list[u]\n",
    "        except:\n",
    "            continue\n",
    "        totalText.append(textExtracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "7\n",
      "3\n",
      "8\n",
      "4\n",
      "9\n",
      "5\n",
      "10\n",
      "6\n",
      "11\n",
      "7\n",
      "12\n",
      "8\n",
      "12\n",
      "9\n",
      "13\n",
      "10\n",
      "14\n",
      "11\n",
      "15\n",
      "12\n",
      "16\n",
      "13\n",
      "15\n",
      "14\n",
      "16\n",
      "15\n",
      "17\n",
      "16\n",
      "17\n",
      "17\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "20\n",
      "20\n",
      "30\n",
      "21\n",
      "31\n",
      "22\n",
      "32\n",
      "23\n",
      "33\n",
      "24\n",
      "34\n",
      "25\n",
      "35\n",
      "26\n",
      "36\n",
      "27\n",
      "37\n",
      "28\n",
      "38\n",
      "29\n",
      "39\n",
      "30\n",
      "40\n",
      "32\n",
      "33\n",
      "33\n",
      "34\n",
      "34\n",
      "35\n",
      "35\n",
      "36\n",
      "38\n",
      "39\n",
      "39\n",
      "40\n",
      "40\n",
      "42\n",
      "41\n",
      "43\n",
      "42\n",
      "44\n",
      "43\n",
      "44\n",
      "44\n",
      "45\n",
      "45\n",
      "46\n",
      "46\n",
      "47\n",
      "47\n",
      "56\n",
      "48\n",
      "57\n",
      "49\n",
      "58\n",
      "50\n",
      "59\n",
      "51\n",
      "60\n",
      "52\n",
      "61\n",
      "53\n",
      "62\n",
      "54\n",
      "63\n",
      "55\n",
      "64\n",
      "56\n",
      "65\n",
      "57\n",
      "59\n",
      "58\n",
      "60\n",
      "59\n",
      "61\n",
      "60\n",
      "61\n",
      "61\n",
      "62\n",
      "62\n",
      "63\n",
      "63\n",
      "64\n",
      "64\n",
      "66\n",
      "65\n",
      "67\n",
      "66\n",
      "68\n",
      "67\n",
      "68\n",
      "68\n",
      "69\n",
      "69\n",
      "73\n",
      "70\n",
      "74\n",
      "71\n",
      "75\n",
      "72\n",
      "76\n",
      "73\n",
      "77\n",
      "74\n",
      "75\n",
      "75\n",
      "76\n",
      "76\n",
      "77\n",
      "77\n",
      "78\n",
      "78\n",
      "79\n",
      "79\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "totalText = []\n",
    "for u in range(len(pagesList)):\n",
    "    textExtracted = \"\"\n",
    "    if pagesList[u] == 1:\n",
    "        textExtracted = text_list[u]\n",
    "        #print(\"Added \" + text_list[u][:10])\n",
    "    else:\n",
    "        print(u)\n",
    "        for h in range(pagesList[u]):\n",
    "            if (u+h == len(text_list)):\n",
    "                break\n",
    "            if (isinstance(text_list[u+h], str) == False):\n",
    "                continue\n",
    "            textExtracted = textExtracted + \"\\n\" + text_list[u+h]\n",
    "        u += h\n",
    "        print(u)\n",
    "    totalText.append(textExtracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(totalText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalText[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-e4a9e48d0e2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpagesList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "DOESNT WORK TO GET ALL PAGES TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Var Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Name for text Files = \n",
      "Total: 54\n"
     ]
    }
   ],
   "source": [
    "print(\"Variable Name for text Files = \")\n",
    "varNameL = []\n",
    "for n, val in enumerate(textList):\n",
    "    globals()[\"text%d\"%n] = val\n",
    "    varNameL.append(\"text%d\"%n)\n",
    "    #print(\"text%d\"%n)\n",
    "print(\"Total: \" + str(n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SENTENCE SPLITTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentences(totalText):\n",
    "    raw_text = totalText\n",
    "    nlp = English()\n",
    "    nlp.add_pipe(nlp.create_pipe('sentencizer')) # updated\n",
    "    doc = nlp(raw_text)\n",
    "    sentences = [sent.string.strip() for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitsentencespart2(totalText):\n",
    "    sentences = [i for i in nlp(totalText).sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalSentence = []\n",
    "for totalText in textList:\n",
    "    arrayf = splitsentencespart2(totalText)\n",
    "    for i in arrayf:\n",
    "        totalSentence.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(totalSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() \n",
    "  \n",
    "# Creating two columns \n",
    "df['Sentence'] = totalSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/kunal/Documents/ResumeNLPVdart/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('resultsentences.xlsx', index = False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST ENITITY EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emails(doc):\n",
    "    resultlis = []\n",
    "    for token in doc:\n",
    "        if token.like_email:\n",
    "            resultlis.append((token.text,token.idx, token.idx + len(token)))\n",
    "    return resultlis\n",
    "def extract_person_names(doc):\n",
    "    personL = []\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_==\"PERSON\":\n",
    "            personL.append([entity.text, entity.start_char, entity.end_char])\n",
    "    return personL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(textList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in textList:\n",
    "    doc = nlp(i)\n",
    "    EMAILLIST = extract_emails(doc)\n",
    "    email_count = 1\n",
    "    for email, start, end in EMAILLIST:\n",
    "        print(str(email_count) + \":  \" +  email)\n",
    "        email_count+=1\n",
    "    print(\"\\n\")\n",
    "    NAMELIST = extract_person_names(doc)\n",
    "    name_count = 1\n",
    "    for name, start, end in NAMELIST:\n",
    "        print(str(name_count) + \":  \" + name)\n",
    "        name_count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] # 1\n",
    "    doc = nlp(text.lower()) # 2\n",
    "    for token in doc:\n",
    "        # 3\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        # 4\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "                \n",
    "    return result # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenserflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyperscince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "setnecnceAuto = []\n",
    "for line in textList[5].splitlines():\n",
    "    setnecnceAuto.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\n",
    "sentenceList = []\n",
    "for j in range(len(setnecnceAuto)):\n",
    "    addword = input(\"Current: >>>\"+ sentence+ \"<<< + >>>\"+ setnecnceAuto[j] + \"<<<\")\n",
    "    if addword == \"\":\n",
    "        sentence += setnecnceAuto[j] + \" \"\n",
    "    elif addword == \"g\":\n",
    "        sentenceList.append(sentence[:-1])\n",
    "        print(\"Added >>>\"+sentence[:-1]+\"<<<\")\n",
    "        sentence = \"\"\n",
    "        setnecnceAuto[j: j] = [\"testfff\"]\n",
    "    elif addword == \"fff\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"\"\n",
    "setnecnceAuto = []\n",
    "for i in textList[5]:\n",
    "    if not (i == \"\\n\"):\n",
    "        word += i \n",
    "    else:\n",
    "        listofWords.append(word)\n",
    "        word = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft\n",
      "CERTIFIED\n",
      "aws certified\n",
      "Professional\n",
      "Hem Chandra\n",
      "Rockville, Maryland\n",
      "469-436-9015\n",
      "manoj@centillioninfotech.com\n",
      "OBJECTIVE:\n",
      "Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET,\n",
      "ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ,\n",
      "XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various desktop\n",
      "and web applications.\n",
      "SUMMARY:\n",
      "Working experience on ASP.NET, ASP.NET MVC framework, Web API and Entity Framework.\n",
      "Working experience on SharePoint 2013 and SharePoint 2010.\n",
      "Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load balancing & Lambda etc.).\n",
      "Understanding of Microsoft Azure Cloud (Design, Deployment, app services, Azure Functions etc.).\n",
      "Extensive experience in coding using C# and VB.NET\n",
      "Implementation experience of various designs patterns (GOF).\n",
      "Involved in Creation, Development and Deployment of SSIS packages in SQL Server.\n",
      "Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate\n",
      "changes to Transaction Isolation levels\n",
      "Database Performance of Index tuning with using Database Engine Tuning Advisor to resolve Performance issues.\n",
      "Performed and fine-tuned Stored Procedures, SQL Queries and User Defined Functions.\n",
      "Extensive experience in developing UML Models using Visio and Rational Rose.\n",
      "Practical experience to implement SOA (Service Oriented Architecture: WCF) and Three-tier architecture.\n",
      "Methodology: AGILE, Scrum, Test Driven Development.\n",
      "Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, branching &\n",
      "merging etc.)\n",
      "Vertical/Domain Experience: Travel, Banking, Insurance, Chemical, Water and Energy\n",
      "Proficiently learned new technology Angular to meet client need.\n",
      "PROFESSIONAL EXPERIENCE\n",
      "Maryland Department of Labor\n",
      "Lead Developer\n",
      "Description:\n",
      "Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those\n",
      "foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies\n",
      "using Nationwide Multistate Licensing System & Registry (NMLS). Application is divided into three sub-systems.\n",
      "1. NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to\n",
      "borrower thorough email as well as by post. User can also upload predefined csv files for bulk submission. SSIS\n",
      "package reads and saves data into database. System sends processed NOI status email to user.\n",
      "2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF to\n",
      "borrower through email.\n",
      "3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of foreclosed property.\n",
      "Payment is done by PayPal payment gateway.\n",
      "User can access the system by https://www.dllr.state.md.us/ForeclosureSystems/\n",
      "Responsibilities:\n",
      "Analysis of requirement.\n",
      "NMLS and PayPal payment gateway integration.\n",
      "Application designing and coding\n",
      "Database designing and writing stored procedures.\n",
      "Oct 2018 – Present\n",
      "Client\n"
     ]
    }
   ],
   "source": [
    "print(textList[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"\"\n",
    "listofWords = []\n",
    "for i in textList[5]:\n",
    "    if not (i == \" \" or i == \"\\n\"):\n",
    "        word += i \n",
    "    else:\n",
    "        listofWords.append(word)\n",
    "        word = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: >>><<< + >>>Microsoft<<<\n",
      "Current: >>>Microsoft <<< + >>>CERTIFIED<<<\n",
      "Current: >>>Microsoft CERTIFIED <<< + >>>aws<<<g\n",
      "Added >>>Microsoft CERTIFIED<<<\n",
      "Current: >>><<< + >>>aws<<<\n",
      "Current: >>>aws <<< + >>>certified<<<\n",
      "Current: >>>aws certified <<< + >>>Professional<<<g\n",
      "Added >>>aws certified<<<\n",
      "Current: >>><<< + >>>Professional<<<\n",
      "Current: >>>Professional <<< + >>>Hem<<<g\n",
      "Added >>>Professional<<<\n",
      "Current: >>><<< + >>>Hem<<<\n",
      "Current: >>>Hem <<< + >>>Chandra<<<\n",
      "Current: >>>Hem Chandra <<< + >>>Rockville,<<<g\n",
      "Added >>>Hem Chandra<<<\n",
      "Current: >>><<< + >>>Rockville,<<<\n",
      "Current: >>>Rockville, <<< + >>>Maryland<<<\n",
      "Current: >>>Rockville, Maryland <<< + >>>469-436-9015<<<g\n",
      "Added >>>Rockville, Maryland<<<\n",
      "Current: >>><<< + >>>469-436-9015<<<\n",
      "Current: >>>469-436-9015 <<< + >>>manoj@centillioninfotech.com<<<g\n",
      "Added >>>469-436-9015<<<\n",
      "Current: >>><<< + >>>manoj@centillioninfotech.com<<<\n",
      "Current: >>>manoj@centillioninfotech.com <<< + >>>OBJECTIVE:<<<g\n",
      "Added >>>manoj@centillioninfotech.com<<<\n",
      "Current: >>><<< + >>>OBJECTIVE:<<<\n",
      "Current: >>>OBJECTIVE: <<< + >>>Lead<<<\n",
      "Current: >>>OBJECTIVE: Lead <<< + >>>Developer<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer <<< + >>>with<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with <<< + >>>more<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more <<< + >>>than<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than <<< + >>>15+<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ <<< + >>>years<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years <<< + >>>of<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of <<< + >>>experience<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience <<< + >>>in<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in <<< + >>>full-stack<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack <<< + >>>development<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development <<< + >>>(C#,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, <<< + >>>VB.NET,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, <<< + >>>.Net,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, <<< + >>>ASP.NET,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, <<< + >>>ASP.NET<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET <<< + >>>MVC,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, <<< + >>>Web<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web <<< + >>>API,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, <<< + >>>Angular,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, <<< + >>>AWS,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, <<< + >>>SharePoint,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, <<< + >>>InfoPath,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, <<< + >>>SQL<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL <<< + >>>Server,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, <<< + >>>SSIS,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, <<< + >>>SSRS,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, <<< + >>>Web<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web <<< + >>>services,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, <<< + >>>WCF,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, <<< + >>>LINQ,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, <<< + >>>XML,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, <<< + >>>TFS<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS <<< + >>>2010/13,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, <<< + >>>SVN,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, <<< + >>>VSS,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, <<< + >>>GitHub,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, <<< + >>>Telerik<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik <<< + >>>Controls,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, <<< + >>>UML,<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, <<< + >>>JQuery<<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery <<< + >>>and<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and <<< + >>>JavaScript)<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) <<< + >>>for<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for <<< + >>>building<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building <<< + >>>various<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various <<< + >>>desktop<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various desktop <<< + >>>and<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various desktop and <<< + >>>web<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various desktop and web <<< + >>>applications.<<<\n",
      "Current: >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various desktop and web applications. <<< + >>>SUMMARY:<<<g\n",
      "Added >>>OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various desktop and web applications.<<<\n",
      "Current: >>><<< + >>>SUMMARY:<<<\n",
      "Current: >>>SUMMARY: <<< + >>>Working<<<g\n",
      "Added >>>SUMMARY:<<<\n",
      "Current: >>><<< + >>>Working<<<\n",
      "Current: >>>Working <<< + >>>experience<<<\n",
      "Current: >>>Working experience <<< + >>>on<<<\n",
      "Current: >>>Working experience on <<< + >>>ASP.NET,<<<\n",
      "Current: >>>Working experience on ASP.NET, <<< + >>>ASP.NET<<<\n",
      "Current: >>>Working experience on ASP.NET, ASP.NET <<< + >>>MVC<<<\n",
      "Current: >>>Working experience on ASP.NET, ASP.NET MVC <<< + >>>framework,<<<\n",
      "Current: >>>Working experience on ASP.NET, ASP.NET MVC framework, <<< + >>>Web<<<\n",
      "Current: >>>Working experience on ASP.NET, ASP.NET MVC framework, Web <<< + >>>API<<<\n",
      "Current: >>>Working experience on ASP.NET, ASP.NET MVC framework, Web API <<< + >>>and<<<\n",
      "Current: >>>Working experience on ASP.NET, ASP.NET MVC framework, Web API and <<< + >>>Entity<<<\n",
      "Current: >>>Working experience on ASP.NET, ASP.NET MVC framework, Web API and Entity <<< + >>>Framework.<<<\n",
      "Current: >>>Working experience on ASP.NET, ASP.NET MVC framework, Web API and Entity Framework. <<< + >>>Working<<<g\n",
      "Added >>>Working experience on ASP.NET, ASP.NET MVC framework, Web API and Entity Framework.<<<\n",
      "Current: >>><<< + >>>Working<<<\n",
      "Current: >>>Working <<< + >>>experience<<<\n",
      "Current: >>>Working experience <<< + >>>on<<<\n",
      "Current: >>>Working experience on <<< + >>>SharePoint<<<\n",
      "Current: >>>Working experience on SharePoint <<< + >>>2013<<<\n",
      "Current: >>>Working experience on SharePoint 2013 <<< + >>>and<<<\n",
      "Current: >>>Working experience on SharePoint 2013 and <<< + >>>SharePoint<<<\n",
      "Current: >>>Working experience on SharePoint 2013 and SharePoint <<< + >>>2010.<<<\n",
      "Current: >>>Working experience on SharePoint 2013 and SharePoint 2010. <<< + >>>Proficiently<<<g\n",
      "Added >>>Working experience on SharePoint 2013 and SharePoint 2010.<<<\n",
      "Current: >>><<< + >>>Proficiently<<<\n",
      "Current: >>>Proficiently <<< + >>>learned<<<\n",
      "Current: >>>Proficiently learned <<< + >>>AWS<<<\n",
      "Current: >>>Proficiently learned AWS <<< + >>>(Design,<<<\n",
      "Current: >>>Proficiently learned AWS (Design, <<< + >>>Deployment,<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, <<< + >>>AWS<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS <<< + >>>EC2,<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, <<< + >>>S3,<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, <<< + >>>Cloud<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud <<< + >>>watch,<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, <<< + >>>Load<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load <<< + >>>balancing<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load balancing <<< + >>>&<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load balancing & <<< + >>>Lambda<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load balancing & Lambda <<< + >>>etc.).<<<\n",
      "Current: >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load balancing & Lambda etc.). <<< + >>>Understanding<<<g\n",
      "Added >>>Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load balancing & Lambda etc.).<<<\n",
      "Current: >>><<< + >>>Understanding<<<\n",
      "Current: >>>Understanding <<< + >>>of<<<\n",
      "Current: >>>Understanding of <<< + >>>Microsoft<<<\n",
      "Current: >>>Understanding of Microsoft <<< + >>>Azure<<<\n",
      "Current: >>>Understanding of Microsoft Azure <<< + >>>Cloud<<<\n",
      "Current: >>>Understanding of Microsoft Azure Cloud <<< + >>>(Design,<<<\n",
      "Current: >>>Understanding of Microsoft Azure Cloud (Design, <<< + >>>Deployment,<<<\n",
      "Current: >>>Understanding of Microsoft Azure Cloud (Design, Deployment, <<< + >>>app<<<\n",
      "Current: >>>Understanding of Microsoft Azure Cloud (Design, Deployment, app <<< + >>>services,<<<\n",
      "Current: >>>Understanding of Microsoft Azure Cloud (Design, Deployment, app services, <<< + >>>Azure<<<\n",
      "Current: >>>Understanding of Microsoft Azure Cloud (Design, Deployment, app services, Azure <<< + >>>Functions<<<\n",
      "Current: >>>Understanding of Microsoft Azure Cloud (Design, Deployment, app services, Azure Functions <<< + >>>etc.).<<<\n",
      "Current: >>>Understanding of Microsoft Azure Cloud (Design, Deployment, app services, Azure Functions etc.). <<< + >>>Extensive<<<g\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added >>>Understanding of Microsoft Azure Cloud (Design, Deployment, app services, Azure Functions etc.).<<<\n",
      "Current: >>><<< + >>>Extensive<<<\n",
      "Current: >>>Extensive <<< + >>>experience<<<\n",
      "Current: >>>Extensive experience <<< + >>>in<<<\n",
      "Current: >>>Extensive experience in <<< + >>>coding<<<\n",
      "Current: >>>Extensive experience in coding <<< + >>>using<<<\n",
      "Current: >>>Extensive experience in coding using <<< + >>>C#<<<\n",
      "Current: >>>Extensive experience in coding using C# <<< + >>>and<<<\n",
      "Current: >>>Extensive experience in coding using C# and <<< + >>>VB.NET<<<\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET <<< + >>>Implementation<<<h\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET <<< + >>>experience<<<\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET experience <<< + >>>of<<<\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET experience of <<< + >>>various<<<\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET experience of various <<< + >>>designs<<<\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET experience of various designs <<< + >>>patterns<<<\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET experience of various designs patterns <<< + >>>(GOF).<<<\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET experience of various designs patterns (GOF). <<< + >>>Involved<<<h\n",
      "Current: >>>Extensive experience in coding using C# and VB.NET experience of various designs patterns (GOF). <<< + >>>in<<<g\n",
      "Added >>>Extensive experience in coding using C# and VB.NET experience of various designs patterns (GOF).<<<\n",
      "Current: >>><<< + >>>in<<<\n",
      "Current: >>>in <<< + >>>Creation,<<<\n",
      "Current: >>>in Creation, <<< + >>>Development<<<\n",
      "Current: >>>in Creation, Development <<< + >>>and<<<\n",
      "Current: >>>in Creation, Development and <<< + >>>Deployment<<<\n",
      "Current: >>>in Creation, Development and Deployment <<< + >>>of<<<\n",
      "Current: >>>in Creation, Development and Deployment of <<< + >>>SSIS<<<\n",
      "Current: >>>in Creation, Development and Deployment of SSIS <<< + >>>packages<<<\n",
      "Current: >>>in Creation, Development and Deployment of SSIS packages <<< + >>>in<<<\n",
      "Current: >>>in Creation, Development and Deployment of SSIS packages in <<< + >>>SQL<<<\n",
      "Current: >>>in Creation, Development and Deployment of SSIS packages in SQL <<< + >>>Server.<<<\n",
      "Current: >>>in Creation, Development and Deployment of SSIS packages in SQL Server. <<< + >>>Used<<<g\n",
      "Added >>>in Creation, Development and Deployment of SSIS packages in SQL Server.<<<\n",
      "Current: >>><<< + >>>Used<<<\n",
      "Current: >>>Used <<< + >>>SQL<<<\n",
      "Current: >>>Used SQL <<< + >>>Profiler<<<\n",
      "Current: >>>Used SQL Profiler <<< + >>>for<<<\n",
      "Current: >>>Used SQL Profiler for <<< + >>>Performance<<<\n",
      "Current: >>>Used SQL Profiler for Performance <<< + >>>monitor<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor <<< + >>>to<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to <<< + >>>resolve<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve <<< + >>>Dead<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead <<< + >>>Locks<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks <<< + >>>and<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and <<< + >>>long<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long <<< + >>>running<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running <<< + >>>queries<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries <<< + >>>by<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by <<< + >>>checking<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking <<< + >>>appropriate<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate <<< + >>>changes<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate changes <<< + >>>to<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate changes to <<< + >>>Transaction<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate changes to Transaction <<< + >>>Isolation<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate changes to Transaction Isolation <<< + >>>levels<<<\n",
      "Current: >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate changes to Transaction Isolation levels <<< + >>>Database<<<g\n",
      "Added >>>Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate changes to Transaction Isolation levels<<<\n",
      "Current: >>><<< + >>>Database<<<\n",
      "Current: >>>Database <<< + >>>Performance<<<\n",
      "Current: >>>Database Performance <<< + >>>of<<<\n",
      "Current: >>>Database Performance of <<< + >>>Index<<<\n",
      "Current: >>>Database Performance of Index <<< + >>>tuning<<<\n",
      "Current: >>>Database Performance of Index tuning <<< + >>>with<<<\n",
      "Current: >>>Database Performance of Index tuning with <<< + >>>using<<<\n",
      "Current: >>>Database Performance of Index tuning with using <<< + >>>Database<<<\n",
      "Current: >>>Database Performance of Index tuning with using Database <<< + >>>Engine<<<\n",
      "Current: >>>Database Performance of Index tuning with using Database Engine <<< + >>>Tuning<<<\n",
      "Current: >>>Database Performance of Index tuning with using Database Engine Tuning <<< + >>>Advisor<<<\n",
      "Current: >>>Database Performance of Index tuning with using Database Engine Tuning Advisor <<< + >>>to<<<\n",
      "Current: >>>Database Performance of Index tuning with using Database Engine Tuning Advisor to <<< + >>>resolve<<<\n",
      "Current: >>>Database Performance of Index tuning with using Database Engine Tuning Advisor to resolve <<< + >>>Performance<<<\n",
      "Current: >>>Database Performance of Index tuning with using Database Engine Tuning Advisor to resolve Performance <<< + >>>issues.<<<\n",
      "Current: >>>Database Performance of Index tuning with using Database Engine Tuning Advisor to resolve Performance issues. <<< + >>>Performed<<<g\n",
      "Added >>>Database Performance of Index tuning with using Database Engine Tuning Advisor to resolve Performance issues.<<<\n",
      "Current: >>><<< + >>>Performed<<<\n",
      "Current: >>>Performed <<< + >>>and<<<\n",
      "Current: >>>Performed and <<< + >>>fine-tuned<<<\n",
      "Current: >>>Performed and fine-tuned <<< + >>>Stored<<<\n",
      "Current: >>>Performed and fine-tuned Stored <<< + >>>Procedures,<<<\n",
      "Current: >>>Performed and fine-tuned Stored Procedures, <<< + >>>SQL<<<\n",
      "Current: >>>Performed and fine-tuned Stored Procedures, SQL <<< + >>>Queries<<<\n",
      "Current: >>>Performed and fine-tuned Stored Procedures, SQL Queries <<< + >>>and<<<\n",
      "Current: >>>Performed and fine-tuned Stored Procedures, SQL Queries and <<< + >>>User<<<\n",
      "Current: >>>Performed and fine-tuned Stored Procedures, SQL Queries and User <<< + >>>Defined<<<\n",
      "Current: >>>Performed and fine-tuned Stored Procedures, SQL Queries and User Defined <<< + >>>Functions.<<<\n",
      "Current: >>>Performed and fine-tuned Stored Procedures, SQL Queries and User Defined Functions. <<< + >>>Extensive<<<g\n",
      "Added >>>Performed and fine-tuned Stored Procedures, SQL Queries and User Defined Functions.<<<\n",
      "Current: >>><<< + >>>Extensive<<<\n",
      "Current: >>>Extensive <<< + >>>experience<<<\n",
      "Current: >>>Extensive experience <<< + >>>in<<<\n",
      "Current: >>>Extensive experience in <<< + >>>developing<<<\n",
      "Current: >>>Extensive experience in developing <<< + >>>UML<<<\n",
      "Current: >>>Extensive experience in developing UML <<< + >>>Models<<<\n",
      "Current: >>>Extensive experience in developing UML Models <<< + >>>using<<<\n",
      "Current: >>>Extensive experience in developing UML Models using <<< + >>>Visio<<<\n",
      "Current: >>>Extensive experience in developing UML Models using Visio <<< + >>>and<<<\n",
      "Current: >>>Extensive experience in developing UML Models using Visio and <<< + >>>Rational<<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: >>>Extensive experience in developing UML Models using Visio and Rational <<< + >>>Rose.<<<\n",
      "Current: >>>Extensive experience in developing UML Models using Visio and Rational Rose. <<< + >>>Practical<<<g\n",
      "Added >>>Extensive experience in developing UML Models using Visio and Rational Rose.<<<\n",
      "Current: >>><<< + >>>Practical<<<\n",
      "Current: >>>Practical <<< + >>>experience<<<\n",
      "Current: >>>Practical experience <<< + >>>to<<<\n",
      "Current: >>>Practical experience to <<< + >>>implement<<<\n",
      "Current: >>>Practical experience to implement <<< + >>>SOA<<<\n",
      "Current: >>>Practical experience to implement SOA <<< + >>>(Service<<<\n",
      "Current: >>>Practical experience to implement SOA (Service <<< + >>>Oriented<<<\n",
      "Current: >>>Practical experience to implement SOA (Service Oriented <<< + >>>Architecture:<<<\n",
      "Current: >>>Practical experience to implement SOA (Service Oriented Architecture: <<< + >>>WCF)<<<\n",
      "Current: >>>Practical experience to implement SOA (Service Oriented Architecture: WCF) <<< + >>>and<<<\n",
      "Current: >>>Practical experience to implement SOA (Service Oriented Architecture: WCF) and <<< + >>>Three-tier<<<\n",
      "Current: >>>Practical experience to implement SOA (Service Oriented Architecture: WCF) and Three-tier <<< + >>>architecture.<<<\n",
      "Current: >>>Practical experience to implement SOA (Service Oriented Architecture: WCF) and Three-tier architecture. <<< + >>>Methodology:<<<g\n",
      "Added >>>Practical experience to implement SOA (Service Oriented Architecture: WCF) and Three-tier architecture.<<<\n",
      "Current: >>><<< + >>>Methodology:<<<\n",
      "Current: >>>Methodology: <<< + >>>AGILE,<<<\n",
      "Current: >>>Methodology: AGILE, <<< + >>>Scrum,<<<\n",
      "Current: >>>Methodology: AGILE, Scrum, <<< + >>>Test<<<\n",
      "Current: >>>Methodology: AGILE, Scrum, Test <<< + >>>Driven<<<\n",
      "Current: >>>Methodology: AGILE, Scrum, Test Driven <<< + >>>Development.<<<\n",
      "Current: >>>Methodology: AGILE, Scrum, Test Driven Development. <<< + >>>Worked<<<g\n",
      "Added >>>Methodology: AGILE, Scrum, Test Driven Development.<<<\n",
      "Current: >>><<< + >>>Worked<<<\n",
      "Current: >>>Worked <<< + >>>as<<<\n",
      "Current: >>>Worked as <<< + >>>TFS<<<\n",
      "Current: >>>Worked as TFS <<< + >>>administrator<<<\n",
      "Current: >>>Worked as TFS administrator <<< + >>>(TFS<<<\n",
      "Current: >>>Worked as TFS administrator (TFS <<< + >>>Server<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server <<< + >>>setup,<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, <<< + >>>installation,<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, <<< + >>>collection<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, collection <<< + >>>creation,<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, collection creation, <<< + >>>build<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, collection creation, build <<< + >>>automation,<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, <<< + >>>branching<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, branching <<< + >>>&<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, branching & <<< + >>>merging<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, branching & merging <<< + >>>etc.)<<<\n",
      "Current: >>>Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, branching & merging etc.) <<< + >>>Vertical/Domain<<<g\n",
      "Added >>>Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, branching & merging etc.)<<<\n",
      "Current: >>><<< + >>>Vertical/Domain<<<\n",
      "Current: >>>Vertical/Domain <<< + >>>Experience:<<<\n",
      "Current: >>>Vertical/Domain Experience: <<< + >>>Travel,<<<\n",
      "Current: >>>Vertical/Domain Experience: Travel, <<< + >>>Banking,<<<\n",
      "Current: >>>Vertical/Domain Experience: Travel, Banking, <<< + >>>Insurance,<<<\n",
      "Current: >>>Vertical/Domain Experience: Travel, Banking, Insurance, <<< + >>>Chemical,<<<\n",
      "Current: >>>Vertical/Domain Experience: Travel, Banking, Insurance, Chemical, <<< + >>>Water<<<\n",
      "Current: >>>Vertical/Domain Experience: Travel, Banking, Insurance, Chemical, Water <<< + >>>and<<<\n",
      "Current: >>>Vertical/Domain Experience: Travel, Banking, Insurance, Chemical, Water and <<< + >>>Energy<<<\n",
      "Current: >>>Vertical/Domain Experience: Travel, Banking, Insurance, Chemical, Water and Energy <<< + >>>Proficiently<<<g\n",
      "Added >>>Vertical/Domain Experience: Travel, Banking, Insurance, Chemical, Water and Energy<<<\n",
      "Current: >>><<< + >>>Proficiently<<<\n",
      "Current: >>>Proficiently <<< + >>>learned<<<\n",
      "Current: >>>Proficiently learned <<< + >>>new<<<\n",
      "Current: >>>Proficiently learned new <<< + >>>technology<<<\n",
      "Current: >>>Proficiently learned new technology <<< + >>>Angular<<<\n",
      "Current: >>>Proficiently learned new technology Angular <<< + >>>to<<<\n",
      "Current: >>>Proficiently learned new technology Angular to <<< + >>>meet<<<\n",
      "Current: >>>Proficiently learned new technology Angular to meet <<< + >>>client<<<\n",
      "Current: >>>Proficiently learned new technology Angular to meet client <<< + >>>need.<<<\n",
      "Current: >>>Proficiently learned new technology Angular to meet client need. <<< + >>>PROFESSIONAL<<<g\n",
      "Added >>>Proficiently learned new technology Angular to meet client need.<<<\n",
      "Current: >>><<< + >>>PROFESSIONAL<<<\n",
      "Current: >>>PROFESSIONAL <<< + >>>EXPERIENCE<<<\n",
      "Current: >>>PROFESSIONAL EXPERIENCE <<< + >>>Maryland<<<\n",
      "Current: >>>PROFESSIONAL EXPERIENCE Maryland <<< + >>>Department<<<\n",
      "Current: >>>PROFESSIONAL EXPERIENCE Maryland Department <<< + >>>of<<<\n",
      "Current: >>>PROFESSIONAL EXPERIENCE Maryland Department of <<< + >>>Labor<<<\n",
      "Current: >>>PROFESSIONAL EXPERIENCE Maryland Department of Labor <<< + >>>Lead<<<g\n",
      "Added >>>PROFESSIONAL EXPERIENCE Maryland Department of Labor<<<\n",
      "Current: >>><<< + >>>Lead<<<\n",
      "Current: >>>Lead <<< + >>>Developer<<<\n",
      "Current: >>>Lead Developer <<< + >>>Description:<<<g\n",
      "Added >>>Lead Developer<<<\n",
      "Current: >>><<< + >>>Description:<<<\n",
      "Current: >>>Description: <<< + >>>Foreclosure<<<g\n",
      "Added >>>Description:<<<\n",
      "Current: >>><<< + >>>Foreclosure<<<\n",
      "Current: >>>Foreclosure <<< + >>>System-The<<<\n",
      "Current: >>>Foreclosure System-The <<< + >>>Foreclosure<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure <<< + >>>Registration<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration <<< + >>>System<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System <<< + >>>is<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is <<< + >>>a<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a <<< + >>>web-based<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based <<< + >>>application<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application <<< + >>>for<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for <<< + >>>submission<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission <<< + >>>of<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of <<< + >>>those<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those <<< + >>>foreclosure-related<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related <<< + >>>notices<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices <<< + >>>and<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and <<< + >>>registrations<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations <<< + >>>that<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that <<< + >>>are<<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are <<< + >>>mandated<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated <<< + >>>by<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by <<< + >>>Maryland<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland <<< + >>>law.<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. <<< + >>>System<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System <<< + >>>verifies<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies <<< + >>>lender<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender <<< + >>>companies<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies <<< + >>>using<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using <<< + >>>Nationwide<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide <<< + >>>Multistate<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide Multistate <<< + >>>Licensing<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide Multistate Licensing <<< + >>>System<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide Multistate Licensing System <<< + >>>&<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide Multistate Licensing System & <<< + >>>Registry<<<\n",
      "Current: >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide Multistate Licensing System & Registry <<< + >>>(NMLS).<<<g\n",
      "Added >>>Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide Multistate Licensing System & Registry<<<\n",
      "Current: >>><<< + >>>(NMLS).<<<\n",
      "Current: >>>(NMLS). <<< + >>>Application<<<\n",
      "Current: >>>(NMLS). Application <<< + >>>is<<<\n",
      "Current: >>>(NMLS). Application is <<< + >>>divided<<<\n",
      "Current: >>>(NMLS). Application is divided <<< + >>>into<<<\n",
      "Current: >>>(NMLS). Application is divided into <<< + >>>three<<<\n",
      "Current: >>>(NMLS). Application is divided into three <<< + >>>sub-systems.<<<\n",
      "Current: >>>(NMLS). Application is divided into three sub-systems. <<< + >>>1.<<<\n",
      "Current: >>>(NMLS). Application is divided into three sub-systems. 1. <<< + >>>NOI<<<g\n",
      "Added >>>(NMLS). Application is divided into three sub-systems. 1.<<<\n",
      "Current: >>><<< + >>>NOI<<<\n",
      "Current: >>>NOI <<< + >>>(Notice<<<\n",
      "Current: >>>NOI (Notice <<< + >>>of<<<\n",
      "Current: >>>NOI (Notice of <<< + >>>Intent<<<\n",
      "Current: >>>NOI (Notice of Intent <<< + >>>to<<<\n",
      "Current: >>>NOI (Notice of Intent to <<< + >>>Foreclose):<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): <<< + >>>Lender<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender <<< + >>>companies<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies <<< + >>>can<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can <<< + >>>submit<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit <<< + >>>NOI<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI <<< + >>>to<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to <<< + >>>DLLR.<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. <<< + >>>Notice<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice <<< + >>>is<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is <<< + >>>created<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created <<< + >>>in<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in <<< + >>>pdf<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf <<< + >>>and<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and <<< + >>>send<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send <<< + >>>to<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to <<< + >>>borrower<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower <<< + >>>thorough<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough <<< + >>>email<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email <<< + >>>as<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as <<< + >>>well<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well <<< + >>>as<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as <<< + >>>by<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by <<< + >>>post.<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. <<< + >>>User<<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User <<< + >>>can<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can <<< + >>>also<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also <<< + >>>upload<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload <<< + >>>predefined<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined <<< + >>>csv<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined csv <<< + >>>files<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined csv files <<< + >>>for<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined csv files for <<< + >>>bulk<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined csv files for bulk <<< + >>>submission.<<<\n",
      "Current: >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined csv files for bulk submission. <<< + >>>SSIS<<<g\n",
      "Added >>>NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined csv files for bulk submission.<<<\n",
      "Current: >>><<< + >>>SSIS<<<\n",
      "Current: >>>SSIS <<< + >>>package<<<\n",
      "Current: >>>SSIS package <<< + >>>reads<<<\n",
      "Current: >>>SSIS package reads <<< + >>>and<<<\n",
      "Current: >>>SSIS package reads and <<< + >>>saves<<<\n",
      "Current: >>>SSIS package reads and saves <<< + >>>data<<<\n",
      "Current: >>>SSIS package reads and saves data <<< + >>>into<<<\n",
      "Current: >>>SSIS package reads and saves data into <<< + >>>database.<<<\n",
      "Current: >>>SSIS package reads and saves data into database. <<< + >>>System<<<\n",
      "Current: >>>SSIS package reads and saves data into database. System <<< + >>>sends<<<\n",
      "Current: >>>SSIS package reads and saves data into database. System sends <<< + >>>processed<<<\n",
      "Current: >>>SSIS package reads and saves data into database. System sends processed <<< + >>>NOI<<<\n",
      "Current: >>>SSIS package reads and saves data into database. System sends processed NOI <<< + >>>status<<<\n",
      "Current: >>>SSIS package reads and saves data into database. System sends processed NOI status <<< + >>>email<<<\n",
      "Current: >>>SSIS package reads and saves data into database. System sends processed NOI status email <<< + >>>to<<<\n",
      "Current: >>>SSIS package reads and saves data into database. System sends processed NOI status email to <<< + >>>user.<<<\n",
      "Current: >>>SSIS package reads and saves data into database. System sends processed NOI status email to user. <<< + >>>2.<<<g\n",
      "Added >>>SSIS package reads and saves data into database. System sends processed NOI status email to user.<<<\n",
      "Current: >>><<< + >>>2.<<<\n",
      "Current: >>>2. <<< + >>>NOF<<<\n",
      "Current: >>>2. NOF <<< + >>>(Notice<<<\n",
      "Current: >>>2. NOF (Notice <<< + >>>of<<<\n",
      "Current: >>>2. NOF (Notice of <<< + >>>Foreclosure<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure <<< + >>>Filing):<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): <<< + >>>Lender<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender <<< + >>>submits<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits <<< + >>>NOF<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF <<< + >>>in<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in <<< + >>>the<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the <<< + >>>system<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system <<< + >>>which<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which <<< + >>>creates<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates <<< + >>>notice<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice <<< + >>>in<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in <<< + >>>pdf<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf <<< + >>>and<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and <<< + >>>sends<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends <<< + >>>NOF<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF <<< + >>>to<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF to <<< + >>>borrower<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF to borrower <<< + >>>through<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF to borrower through <<< + >>>email.<<<\n",
      "Current: >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF to borrower through email. <<< + >>>3.<<<g\n",
      "Added >>>2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF to borrower through email.<<<\n",
      "Current: >>><<< + >>>3.<<<\n",
      "Current: >>>3. <<< + >>>FPR<<<\n",
      "Current: >>>3. FPR <<< + >>>(Foreclosed<<<\n",
      "Current: >>>3. FPR (Foreclosed <<< + >>>Property<<<\n",
      "Current: >>>3. FPR (Foreclosed Property <<< + >>>Registration):<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): <<< + >>>Lender<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender <<< + >>>company<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company <<< + >>>admin<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin <<< + >>>submits<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits <<< + >>>property<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property <<< + >>>registration<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration <<< + >>>of<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of <<< + >>>foreclosed<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of foreclosed <<< + >>>property.<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of foreclosed property. <<< + >>>Payment<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of foreclosed property. Payment <<< + >>>is<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of foreclosed property. Payment is <<< + >>>done<<<\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of foreclosed property. Payment is done <<< + >>>by<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of foreclosed property. Payment is done by <<< + >>>PayPal<<<\n",
      "Current: >>>3. FPR (Foreclosed Property Registration): Lender company admin submits property registration of foreclosed property. Payment is done by PayPal <<< + >>>payment<<<\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\n",
    "sentenceList = []\n",
    "for j in range(len(listofWords)):\n",
    "    #print(listofWords[j])\n",
    "    #print(\"running \" + listofWords[j])\n",
    "    addword = input(\"Current: >>>\"+ sentence+ \"<<< + >>>\"+ listofWords[j] + \"<<<\")\n",
    "    if addword == \"\":\n",
    "        sentence += listofWords[j] + \" \"\n",
    "    elif addword == \"g\":\n",
    "        sentenceList.append(sentence[:-1])\n",
    "        print(\"Added >>>\"+sentence[:-1]+\"<<<\")\n",
    "        sentence = \"\"\n",
    "        listofWords[j: j] = [\"testfff\"]\n",
    "    elif addword == \"fff\":\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft CERTIFIED',\n",
       " 'aws certified',\n",
       " 'Professional',\n",
       " 'Hem Chandra',\n",
       " 'Rockville, Maryland',\n",
       " '469-436-9015',\n",
       " 'manoj@centillioninfotech.com',\n",
       " 'OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various desktop and web applications.',\n",
       " 'SUMMARY:',\n",
       " 'Working experience on ASP.NET, ASP.NET MVC framework, Web API and Entity Framework.',\n",
       " 'Working experience on SharePoint 2013 and SharePoint 2010.',\n",
       " 'Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load balancing & Lambda etc.).',\n",
       " 'Understanding of Microsoft Azure Cloud (Design, Deployment, app services, Azure Functions etc.).',\n",
       " 'Extensive experience in coding using C# and VB.NET experience of various designs patterns (GOF).',\n",
       " 'in Creation, Development and Deployment of SSIS packages in SQL Server.',\n",
       " 'Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate changes to Transaction Isolation levels',\n",
       " 'Database Performance of Index tuning with using Database Engine Tuning Advisor to resolve Performance issues.',\n",
       " 'Performed and fine-tuned Stored Procedures, SQL Queries and User Defined Functions.',\n",
       " 'Extensive experience in developing UML Models using Visio and Rational Rose.',\n",
       " 'Practical experience to implement SOA (Service Oriented Architecture: WCF) and Three-tier architecture.',\n",
       " 'Methodology: AGILE, Scrum, Test Driven Development.',\n",
       " 'Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, branching & merging etc.)',\n",
       " 'Vertical/Domain Experience: Travel, Banking, Insurance, Chemical, Water and Energy',\n",
       " 'Proficiently learned new technology Angular to meet client need.',\n",
       " 'PROFESSIONAL EXPERIENCE Maryland Department of Labor',\n",
       " 'Lead Developer',\n",
       " 'Description:',\n",
       " 'Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide Multistate Licensing System & Registry',\n",
       " '(NMLS). Application is divided into three sub-systems. 1.',\n",
       " 'NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined csv files for bulk submission.',\n",
       " 'SSIS package reads and saves data into database. System sends processed NOI status email to user.',\n",
       " '2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF to borrower through email.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"sentenceList.append(\"Tested and troubleshot configurations in the console to check the communication between the networks.\")\n",
    "sentenceList.append(\"Design of X-Band 8PSK Modulator using ADS\")\n",
    "sentenceList.append(\"Jan 2017 - April 2017\")\n",
    "sentenceList.append(\"Designed various components of the modulator used in a satellite at ISRO (Indian Space Research Organization), Bangalore.\")\n",
    "sentenceList.append(\"Performed optimization of the components at 8.75GHz frequency using the tools available in ADS to obtain the desired results of Insertion loss, Return loss and Isolation loss.\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentenceList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL SENTENCE LIST MADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceList = ['Microsoft CERTIFIED',\n",
    " 'aws certified',\n",
    " 'Professional',\n",
    " 'Hem Chandra',\n",
    " 'Rockville, Maryland',\n",
    " '469-436-9015',\n",
    " 'manoj@centillioninfotech.com',\n",
    " 'OBJECTIVE: Lead Developer with more than 15+ years of experience in full-stack development (C#, VB.NET, .Net, ASP.NET, ASP.NET MVC, Web API, Angular, AWS, SharePoint, InfoPath, SQL Server, SSIS, SSRS, Web services, WCF, LINQ, XML, TFS 2010/13, SVN, VSS, GitHub, Telerik Controls, UML, JQuery and JavaScript) for building various desktop and web applications.',\n",
    " 'SUMMARY:',\n",
    " 'Working experience on ASP.NET, ASP.NET MVC framework, Web API and Entity Framework.',\n",
    " 'Working experience on SharePoint 2013 and SharePoint 2010.',\n",
    " 'Proficiently learned AWS (Design, Deployment, AWS EC2, S3, Cloud watch, Load balancing & Lambda etc.).',\n",
    " 'Understanding of Microsoft Azure Cloud (Design, Deployment, app services, Azure Functions etc.).',\n",
    " 'Extensive experience in coding using C# and VB.NET experience of various designs patterns (GOF).',\n",
    " 'in Creation, Development and Deployment of SSIS packages in SQL Server.',\n",
    " 'Used SQL Profiler for Performance monitor to resolve Dead Locks and long running queries by checking appropriate changes to Transaction Isolation levels',\n",
    " 'Database Performance of Index tuning with using Database Engine Tuning Advisor to resolve Performance issues.',\n",
    " 'Performed and fine-tuned Stored Procedures, SQL Queries and User Defined Functions.',\n",
    " 'Extensive experience in developing UML Models using Visio and Rational Rose.',\n",
    " 'Practical experience to implement SOA (Service Oriented Architecture: WCF) and Three-tier architecture.',\n",
    " 'Methodology: AGILE, Scrum, Test Driven Development.',\n",
    " 'Worked as TFS administrator (TFS Server setup, installation, collection creation, build automation, branching & merging etc.)',\n",
    " 'Vertical/Domain Experience: Travel, Banking, Insurance, Chemical, Water and Energy',\n",
    " 'Proficiently learned new technology Angular to meet client need.',\n",
    " 'PROFESSIONAL EXPERIENCE Maryland Department of Labor',\n",
    " 'Lead Developer',\n",
    " 'Description:',\n",
    " 'Foreclosure System-The Foreclosure Registration System is a web-based application for submission of those foreclosure-related notices and registrations that are mandated by Maryland law. System verifies lender companies using Nationwide Multistate Licensing System & Registry',\n",
    " '(NMLS). Application is divided into three sub-systems. 1.',\n",
    " 'NOI (Notice of Intent to Foreclose): Lender companies can submit NOI to DLLR. Notice is created in pdf and send to borrower thorough email as well as by post. User can also upload predefined csv files for bulk submission.',\n",
    " 'SSIS package reads and saves data into database. System sends processed NOI status email to user.',\n",
    " '2. NOF (Notice of Foreclosure Filing): Lender submits NOF in the system which creates notice in pdf and sends NOF to borrower through email.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sentenceList)\n",
    "df.to_excel(\"sentenceLISTNEW.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create JSON from Array -- NOTWORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributeCount = 3\n",
    "sentenceCount = 2\n",
    "text = \"NISARGA HASSAN SREEDHAR\"\n",
    "attributes = [[\"NAME\", \"NISARGA HASSAN SREEDHAR\", 0, 23],\n",
    "              [\"LOCATION\", \"San Jose, California\", 12, 18],\n",
    "              [\"PROGRAMMING LANGUAGE\", \"PYTHON\", 17, 20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createJSON(attributeCount, sentenceCount, text, attributes):\n",
    "    totalString = \"\"\"\n",
    "    \"sentenceCode\": [\n",
    "        \"text\": \"textCODE\",\n",
    "        \"entities\" : [\n",
    "    attributeCODE\n",
    "        ]\n",
    "    ],\n",
    "    \"\"\"\n",
    "    attributeString = \"\"\"       \"attributeCode\" : {\n",
    "               \"Atribname\": \"AtribnameCODE\",\n",
    "               \"textDetected\": \"textDetectedCODE\",\n",
    "               \"sChar\": sCharCODE,\n",
    "               \"eChar\": eCharCODE\n",
    "           }\n",
    "    \"\"\"\n",
    "    sentenceStringReplacer = \"sentence\" + str(sentenceCount)\n",
    "    totalString =  totalString.replace(\"sentenceCode\", sentenceStringReplacer)\n",
    "    totalString =  totalString.replace(\"textCODE\", text)\n",
    "    tempStringReplacer = \"\"\n",
    "    for i in range(attributeCount):\n",
    "        tempStringReplacer+=(\"atriCODE\"+str(i+1)+\"\\n\")\n",
    "    totalString = totalString.replace(\"attributeCODE\", tempStringReplacer)\n",
    "    for i in range(attributeCount):\n",
    "        attributeStringNEW = attributeString\n",
    "        print(attributes[i])\n",
    "        attributeStringNEW = attributeStringNEW.replace(\"AtribnameCODE\", attributes[i][0]).replace(\"textDetectedCODE\", attributes[i][1])\n",
    "        attributeStringNEW = attributeStringNEW.replace(\"sCharCODE\", str(attributes[i][2])).replace(\"eCharCODE\", str(attributes[i][3]))\n",
    "        totalString = totalString.replace((\"atriCODE\"+str(i+1)), attributeStringNEW)\n",
    "    return totalString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"\n",
    "{\n",
    "    \"Document1Sentences\" : [\n",
    "        \"sentence1\": [\n",
    "            \"text\": \"NISARGA HASSAN SREEDHAR\",\n",
    "            \"entities\" : [\n",
    "                \"attribute1\" : {\n",
    "                    \"Atribname\": \"NAME\",\n",
    "                    \"textDetected\": \"NISARGA HASSAN SREEDHAR\",\n",
    "                    \"sChar\": 0,\n",
    "                    \"eChar\": 23\n",
    "                }\n",
    "            ]\n",
    "        ],\n",
    "        \"sentence2\": [\n",
    "            \"text\": \"San Jose, California\",\n",
    "            \"entities\" : [\n",
    "                \"attribute1\" : {\n",
    "                    \"Atribname\": \"LOCATION\",\n",
    "                    \"textDetected\": \"San Jose, California\",\n",
    "                    \"sChar\": 0,\n",
    "                    \"eChar\": 18\n",
    "                }\n",
    "            ]\n",
    "        ],\n",
    "        \"sentence3\": [\n",
    "            \"text\": \"Programming: Python, Java\",\n",
    "            \"entities\" : [\n",
    "                \"attribute1\" : {\n",
    "                    \"Atribname\": \"Programming Language\",\n",
    "                    \"textDetected\": \"Python\",\n",
    "                    \"sChar\": 13,\n",
    "                    \"eChar\": 18\n",
    "                },\n",
    "                \"attribute2\" : {\n",
    "                    \"Atribname\": \"Programming Language\",\n",
    "                    \"textDetected\": \"Java\",\n",
    "                    \"sChar\": 20,\n",
    "                    \"eChar\": 24\n",
    "                }\n",
    "            ]\n",
    "        ],\n",
    "        \"sentence4\": [\n",
    "            \"text\": \"Aug 2019 - Dec 2019\",\n",
    "            \"entities\" : [\n",
    "                \"attribute1\" : {\n",
    "                    \"Atribname\": \"DATE\",\n",
    "                    \"textDetected\": \"Aug 2019\",\n",
    "                    \"sChar\": 0,\n",
    "                    \"eChar\": 12\n",
    "                },\n",
    "                \"attribute2\" : {\n",
    "                    \"Atribname\": \"DATE\",\n",
    "                    \"textDetected\": \"Dec 2019\",\n",
    "                    \"sChar\": 16,\n",
    "                    \"eChar\": 20\n",
    "                }\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Attributes for each Sentence in Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sentenceList:\n",
    "    print(checkattributes(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPACY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkattributes(text):\n",
    "    doc = nlp(text)\n",
    "    EMAILLIST = extract_emails(doc)\n",
    "    NAMELIST = extract_person_names(doc)\n",
    "    #print(NAMELIST)\n",
    "    #print(EMAILLIST)\n",
    "    if (NAMELIST == [] and not EMAILLIST == []) or (not EMAILLIST == [] and not NAMELIST == []):\n",
    "        return [\"EMAIL\", EMAILLIST[0][0], EMAILLIST[0][1], EMAILLIST[0][2]]\n",
    "    #elif EMAILLIST == [] and not NAMELIST == []:\n",
    "        #return [\"NAME\", NAMELIST[0][0], NAMELIST[0][1], NAMELIST[0][2]]\n",
    "    #elif NAMELIST == [] and EMAILLIST == []:\n",
    "        #return [\"N/A\", \"\" , 0,  0]\n",
    "    else:\n",
    "        return [\"N/A\", \"\" , 0,  0]\n",
    "def extract_emails(doc):\n",
    "    resultlis = []\n",
    "    for token in doc:\n",
    "        if token.like_email:\n",
    "            resultlis.append((token.text,token.idx, token.idx + len(token)))\n",
    "    return resultlis\n",
    "def extract_person_names(doc):\n",
    "    personL = []\n",
    "    for entity in doc.ents:\n",
    "        if entity.label_==\"PERSON\":\n",
    "            personL.append([entity.text, entity.start_char, entity.end_char])\n",
    "    return personL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Array to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Excel and Turn into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/kunal/Documents/ResumeNLPVdart/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.ExcelFile(\"sentenceLISTT.xlsx\")\n",
    "attributes = text.parse(\"Sheet1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NISARGA HASSAN SREEDHAR</td>\n",
       "      <td>Name</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>San Jose, California</td>\n",
       "      <td>Location</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>|+1 (925) 789-8911|</td>\n",
       "      <td>Phone</td>\n",
       "      <td>(925) 789-8911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>nisarga.nishu20@gmail.com</td>\n",
       "      <td>email</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>|</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>Tested and troubleshot configurations in the c...</td>\n",
       "      <td>none</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>Design of X-Band 8PSK Modulator using ADS</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>X-Band 8PSK Modulator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>Jan 2017 - April 2017</td>\n",
       "      <td>Date</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>Designed various components of the modulator u...</td>\n",
       "      <td>Company</td>\n",
       "      <td>ISRO (Indian Space Research Organization)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>Performed optimization of the components at 8....</td>\n",
       "      <td>MultipleSkills</td>\n",
       "      <td>Insertion loss, Return loss and Isolation loss.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text      Unnamed: 1  \\\n",
       "0                             NISARGA HASSAN SREEDHAR            Name   \n",
       "1                                San Jose, California        Location   \n",
       "2                                 |+1 (925) 789-8911|           Phone   \n",
       "3                           nisarga.nishu20@gmail.com           email   \n",
       "4                                                   |            none   \n",
       "..                                                ...             ...   \n",
       "58  Tested and troubleshot configurations in the c...            none   \n",
       "59          Design of X-Band 8PSK Modulator using ADS        Hardware   \n",
       "60                              Jan 2017 - April 2017            Date   \n",
       "61  Designed various components of the modulator u...         Company   \n",
       "62  Performed optimization of the components at 8....  MultipleSkills   \n",
       "\n",
       "                                         Unnamed: 2 Unnamed: 3 Unnamed: 4  \\\n",
       "0                                               All        NaN        NaN   \n",
       "1                                               All        NaN        NaN   \n",
       "2                                    (925) 789-8911        NaN        NaN   \n",
       "3                                               All        NaN        NaN   \n",
       "4                                               NaN        NaN        NaN   \n",
       "..                                              ...        ...        ...   \n",
       "58                                              NaN        NaN        NaN   \n",
       "59                            X-Band 8PSK Modulator        NaN        NaN   \n",
       "60                                              All        NaN        NaN   \n",
       "61        ISRO (Indian Space Research Organization)        NaN        NaN   \n",
       "62  Insertion loss, Return loss and Isolation loss.        NaN        NaN   \n",
       "\n",
       "   Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10  \n",
       "0         NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "1         NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "2         NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "3         NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "4         NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "..        ...        ...        ...        ...        ...         ...  \n",
       "58        NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "59        NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "60        NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "61        NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "62        NaN        NaN        NaN        NaN        NaN         NaN  \n",
       "\n",
       "[63 rows x 11 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RowList = attributes.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributeList = [[i for i in row if isinstance(i,str)] for row in RowList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Final List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totalTextRunning = totalText[0]\n",
    "attributesNumberList = []\n",
    "for j in attributeList:\n",
    "    runningAttributeNum = []\n",
    "    if len(j) == 2:\n",
    "        continue\n",
    "    if j[2] == \"All\":\n",
    "        startChar = totalTextRunning.find(j[0])\n",
    "        endChar = startChar + len(j[0])\n",
    "        runningAttributeNum.extend([j[1], startChar, endChar])\n",
    "    else:\n",
    "        #print(int((len(j)-1)/2))\n",
    "        for w in range(int((len(j)-1)/2)):\n",
    "            startChar = totalTextRunning.find(j[2+w])\n",
    "            endChar = startChar + len(j[2+w])\n",
    "            runningAttributeNum.extend([j[1+w], startChar, endChar])\n",
    "        attributesNumberList.append(runningAttributeNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_2_word(sentence):\n",
    "    word = \"\"\n",
    "    listofWords = []\n",
    "    for i in sentence:\n",
    "        if not (i == \" \" or i == \"\\n\"):\n",
    "            word += i \n",
    "        else:\n",
    "            listofWords.append(word)\n",
    "            word = \"\"\n",
    "    if len(listofWords) == 0:\n",
    "        listofWords.append(sentence)\n",
    "    return listofWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_indexes(input_str, search_str):\n",
    "    l1 = []\n",
    "    length = len(input_str)\n",
    "    index = 0\n",
    "    while index < length:\n",
    "        i = input_str.find(search_str, index)\n",
    "        if i == -1:\n",
    "            return l1\n",
    "        l1.append(i)\n",
    "        index = i + 1\n",
    "    return l1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTextRunning = totalText[0]\n",
    "attributesNumberList = []\n",
    "for j in attributeList:\n",
    "    runningAttributeNum = []\n",
    "    if len(j) == 2:\n",
    "        continue\n",
    "    if j[2] == \"All\":\n",
    "        startChar = totalTextRunning.find(j[0])\n",
    "        endChar = startChar + len(j[0])\n",
    "        runningAttributeNum.extend([j[1].upper() , startChar, endChar])\n",
    "        attributesNumberList.append(runningAttributeNum)\n",
    "    else:\n",
    "        #print(\"RUNNING \" + str(int((len(j)-1)/2)))\n",
    "        for w in range(0, int((len(j)-1)), 2):\n",
    "            runningAttributeNum = []\n",
    "            if not totalTextRunning.find(j[2+w]) == -1:\n",
    "                startChar = totalTextRunning.find(j[2+w])\n",
    "                endChar = startChar + len(j[2+w])\n",
    "                runningAttributeNum.extend([j[1+w].upper(), startChar, endChar])\n",
    "            else:\n",
    "                words = sentence_2_word(j[2+w])\n",
    "                detected = 0\n",
    "                for g in words:\n",
    "                    if not j[2+w].find(g) == -1:\n",
    "                        #charTemp = j[2+w].find(g)\n",
    "                        detected+=1\n",
    "                if detected/len(words) > 0.95:\n",
    "                    startChar = totalTextRunning.find(words[0])\n",
    "                    endChar = startChar + len(words[0])\n",
    "                    runningAttributeNum.extend([words[0].upper(), startChar, endChar])\n",
    "                else:\n",
    "                    charTemp = -1\n",
    "                    print(\"NOT DETECTED\")\n",
    "                    endChar , startChar = -1\n",
    "                    runningAttributeNum.extend([\"NOTDETECTED\", startChar, endChar])\n",
    "            attributesNumberList.append(runningAttributeNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for testing in attributesNumberList:\n",
    "    if testing[1] == -1:\n",
    "        attributesNumberList.remove(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSet to JSON FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributeCount = len(attributesNumberList)\n",
    "text = totalTextRunning\n",
    "attributes = attributesNumberList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createJSONFILE(attributeCount, text, attributes):\n",
    "    totalString = \"\"\"\n",
    "    {\n",
    "        \"annotations\": [\n",
    "            attributeCODE\n",
    "        ],\n",
    "        \"text_snippet\": {\n",
    "            \"content\": \"textCODE\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    \"\"\"\n",
    "    attributeString = \"\"\"       \n",
    "        {\n",
    "          \"text_extraction\": {\n",
    "            \"text_segment\": {\n",
    "              \"end_offset\": eCharCODE,\n",
    "              \"start_offset\": sCharCODE\n",
    "            }\n",
    "          },\n",
    "          \"display_name\": \"AtribnameCODE\"\n",
    "        },\n",
    "    \"\"\"\n",
    "    totalString =  totalString.replace(\"textCODE\", text)\n",
    "    tempStringReplacer = \"\"\n",
    "    for i in range(attributeCount):\n",
    "        tempStringReplacer+=(\"atriCODE\"+str(i+1)+\"\\n\")\n",
    "    totalString = totalString.replace(\"attributeCODE\", tempStringReplacer)\n",
    "    for i in range(attributeCount):\n",
    "        attributeStringNEW = attributeString\n",
    "        #print(attributes[i])\n",
    "        attributeStringNEW = attributeStringNEW.replace(\"AtribnameCODE\", attributes[i][0])\n",
    "        attributeStringNEW = attributeStringNEW.replace(\"sCharCODE\", str(attributes[i][1])).replace(\"eCharCODE\", str(attributes[i][2]))\n",
    "        totalString = totalString.replace((\"atriCODE\"+str(i+1)), attributeStringNEW)\n",
    "    return totalString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Run Create JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    {\n",
      "        \"annotations\": [\n",
      "                   \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 207,\n",
      "              \"start_offset\": 151\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EDUCATION\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 252,\n",
      "              \"start_offset\": 208\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 206,\n",
      "              \"start_offset\": 187\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"SKILL\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 422,\n",
      "              \"start_offset\": 366\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EDUCATION\"\n",
      "        },\n",
      "    \n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    0\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    1\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    2\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    3\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    4\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    5\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    6\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    7\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    8\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 23,\n",
      "              \"start_offset\": 0\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"NAME\"\n",
      "        },\n",
      "    9\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    0\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    1\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    2\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    3\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    4\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    5\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    6\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    7\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    8\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 44,\n",
      "              \"start_offset\": 24\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LOCATION\"\n",
      "        },\n",
      "    9\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    0\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    1\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    2\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    3\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    4\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    5\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    6\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    7\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    8\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 63,\n",
      "              \"start_offset\": 49\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"PHONE\"\n",
      "        },\n",
      "    9\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    0\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    1\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    2\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    3\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    4\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    5\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    6\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    7\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    8\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 90,\n",
      "              \"start_offset\": 65\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EMAIL\"\n",
      "        },\n",
      "    9\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    0\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    1\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    2\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    3\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    4\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    5\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    6\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    7\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    8\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 139,\n",
      "              \"start_offset\": 93\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"LINKEDIN\"\n",
      "        },\n",
      "    9\n",
      "       \n",
      "        {\n",
      "          \"text_extraction\": {\n",
      "            \"text_segment\": {\n",
      "              \"end_offset\": 207,\n",
      "              \"start_offset\": 151\n",
      "            }\n",
      "          },\n",
      "          \"display_name\": \"EDUCATION\"\n",
      "        },\n",
      "    0\n",
      "\n",
      "        ],\n",
      "        \"text_snippet\": {\n",
      "            \"content\": \"NISARGA HASSAN SREEDHAR\n",
      "San Jose, California |+1 (925) 789-8911| nisarga.nishu20@gmail.com | www.linkedin.com/in/nisarga-sreedhar-39938516b\n",
      "EDUCATION:\n",
      "Master's in Electrical Engineering (Computer Networking), San Jose State University, California, USA.\n",
      "Coursework: Internetworking, Broadband communications, Network Security, Internet of Things (IoT), Voice over IP\n",
      "Bachelor of Engineering in Telecommunication Engineering, Dayananda Sagar College of Engineering, Visvesvaraya\n",
      "Technological University, India\n",
      "May 2020\n",
      "June 2017\n",
      "TECHNICAL SKILLS:\n",
      "Network technologies: HTTP, DNS, DHCP, HTTPS, TLS-SSL, TCP/IP, UDP, IPV4, IPV6, ICMP, OSPF, BGP, ARP, VLAN, STP,\n",
      "SIP, IPS, IDS, NAT, IS-IS, 802.11, MPLS, WPA2, WPA3, Packet level troubleshooting\n",
      "Programming: Python\n",
      "OS Platform: Linux (Ubuntu, CentOS), Kali Linux, Cisco IOS\n",
      "Tools and IDE: Advanced Design System (ADS), Wireshark, VMware Workstation, VirtualBox, GNS3, Cisco Packet Tracer, PUTTY\n",
      "CERTIFICATION:\n",
      "Cisco Certified Network Associate (CCNA) 200-301\n",
      "AWS Certified Cloud Practitioner (CLF-C01)\n",
      "(In Progress)\n",
      "(In progress)\n",
      "EXPERIENCE:\n",
      "June 2019 - July 2019\n",
      "Marmon Food & Beverages Technologies, Cornelius, India\n",
      "Network Engineer Intern\n",
      "Python based Serial Communication (IoT)\n",
      "Used an Iot Dongle to read a file, convert it into a packet by adding header and footer and transmit serially.\n",
      "Python code was written to send the file from dongle to Food Holding Bin.\n",
      "ACADEMIC PROJECTS:\n",
      "Secure routing in IoT networks\n",
      "Aug 2019 - current\n",
      "Design and configure an IoT based network using Cisco Packet Tracer.\n",
      "Perform a Man in the Middle attack to one of the devices using Kali Linux.\n",
      "Detection of the attack and solution to the problem faced.\n",
      "Illumino: IoT Smart Light\n",
      "Aug 2019 - Dec 2019\n",
      "Create a hardware of an IoT smart light using Arduino ESP8266 and Cayenne IoT Platform.\n",
      "Designed to operate in three modes: Auto mode, Lamp mode, Security mode.\n",
      "Use of Cayenne web application to detect temperature and provides a siren at thresholds.\n",
      "Voice over IP for Wireless Ad Hoc Networks (WANET)\n",
      "Aug 2019 - Dec 2019\n",
      "Simple Call Establishment between two clients in a WANET that have registered with the Asterisk server.\n",
      "Call on Hold with one user client to attend another client.\n",
      "Call Conferencing between all three clients, all performed using X-Lite softphone software.\n",
      "Experiencing Virtualization using Virtual Box\n",
      "Jan 2019 - April 2019\n",
      "Worked on Open vSwitch in Virtual Box on an Ubuntu machine to run ovs and its versions successfully.\n",
      "Demonstrated how the VLANS are implemented, three VMs and one virtual switch is created.\n",
      "Attempted to communicate between the VMs and observed the PING result.\n",
      "Corporate Company Network Design\n",
      "Aug 2018 - Dec 2018\n",
      "• Designed and implemented a basic corporate network topology for the interconnection between offices with\n",
      "switches, routers, and hosts.\n",
      "• Implemented the design using routing protocols such as OSPF, BGP, DNS, VLAN, STP, IP, DHCP and HSRP.\n",
      "Tested and troubleshot configurations in the console to check the communication between the networks.\n",
      "Design of X-Band 8PSK Modulator using ADS\n",
      "Jan 2017 - April 2017\n",
      "Designed various components of the modulator used in a satellite at ISRO (Indian Space Research Organization), Bangalore.\n",
      "Performed optimization of the components at 8.75GHZ frequency using the tools available in ADS to obtain the desired results of\n",
      "Insertion loss, Return loss and Isolation\"\n",
      "        }\n",
      "    }\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(createJSONFILE(attributeCount, text, attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"\"\"{\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"text_extraction\": {\n",
    "        \"text_segment\": {\n",
    "          \"end_offset\": 67,\n",
    "          \"start_offset\": 62\n",
    "        }\n",
    "      },\n",
    "      \"display_name\": \"Modifier\"\n",
    "    },\n",
    "    {\n",
    "      \"text_extraction\": {\n",
    "        \"text_segment\": {\n",
    "          \"end_offset\": 158,\n",
    "          \"start_offset\": 141\n",
    "        }\n",
    "      },\n",
    "      \"display_name\": \"SpecificDisease\"\n",
    "    }\n",
    "  ],\n",
    "  \"text_snippet\": {\n",
    "    \"content\": \"10051005\\tA common MSH2 mutation in English and North American HNPCC families:\n",
    "      origin, phenotypic expression, and sex specific differences in colorectal cancer .\\tThe\n",
    "      frequency , origin , and phenotypic expression of a germline MSH2 gene mutation previously\n",
    "      identified in seven kindreds with hereditary non-polyposis cancer syndrome (HNPCC) was\n",
    "      investigated . The mutation ( A-- > T at nt943 + 3 ) disrupts the 3 splice site of exon 5\n",
    "      leading to the deletion of this exon from MSH2 mRNA and represents the only frequent MSH2\n",
    "      mutation so far reported . Although this mutation was initially detected in four of 33\n",
    "      colorectal cancer families analysed from eastern England , more extensive analysis has\n",
    "      reduced the frequency to fou\"\n",
    "  }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Creating Loop for creating Sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   NISARGA\n",
      "Does this contain a elementy\n",
      "Add more to this element?y\n",
      "HASSAN\n",
      "Add more to this element?y\n",
      "SREEDHAR\n",
      "San\n",
      "Add more to this element?n\n",
      "HASSAN\n",
      "Add more to this element?n\n",
      "HASSAN\n",
      "Add more to this element?n\n",
      "HASSAN\n",
      "Add more to this element?q\n",
      "HASSAN\n",
      "Add more to this element?x\n",
      "HASSAN\n",
      "Add more to this element?x\n",
      "HASSAN\n",
      "Add more to this element?x\n",
      "HASSAN\n"
     ]
    }
   ],
   "source": [
    "wordCount = 0\n",
    "elementList = []\n",
    "for i in listofWords:\n",
    "    elementGoing = \"\"\n",
    "    print(str(wordCount) +  \"   \" +  i)\n",
    "    elementContain = input(\"Does this contain a element\")\n",
    "    while elementContain == \"\" or not (elementContain == \"n\" or elementContain == \"y\") :\n",
    "        elementContain = input(\"Does this contain a element\")\n",
    "    if elementContain == \"Y\" or elementContain == \"y\":\n",
    "        elementGoing += i\n",
    "        continueaddElement = input(\"Add more to this element?\")\n",
    "        while continueaddElement == \"\":\n",
    "            continueaddElement = input(\"Add more to this element?\")\n",
    "        while continueaddElement == \"Y\" or continueaddElement == \"y\":\n",
    "            print(listofWords[wordCount+1])\n",
    "            countineElement2  = input(\"Add more to this element?\")\n",
    "            while countineElement2 == \"\":\n",
    "                countineElement2 = input(\"Add more to this element?\")\n",
    "            while countineElement2 == \"Y\" or countineElement2 == \"y\":\n",
    "                print(listofWords[wordCount+2])\n",
    "                countineElement2 =  input(\"Add more to this element?\")\n",
    "        if continueaddElement == \"x\":\n",
    "            break\n",
    "    if elementContain == \"x\":\n",
    "        break\n",
    "    wordCount+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a program that goes through the text file and extracts each entity and its starting position and ending position and its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
